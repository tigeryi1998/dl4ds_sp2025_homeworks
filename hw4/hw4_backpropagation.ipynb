{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "2QXB2A_JE1C5"
      },
      "outputs": [],
      "source": [
        "# Initialize Otter\n",
        "import otter\n",
        "grader = otter.Notebook(\"hw4_backpropagation.ipynb\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Name: Sicheng Yi (Tiger Yi)\n",
        "### ID: U43188754\n",
        "### Email: tigeryi@bu.edu\n"
      ],
      "metadata": {
        "id": "eQ-dQINLzWGO"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6chybAVFJW2"
      },
      "source": [
        "# **Notebook 4: Backpropagation**\n",
        "\n",
        "In this notebook we will implement a fully connected neural network manually and\n",
        "then complete forward and backward pass functions. We'll then put it all together\n",
        "in a training loop.\n",
        "\n",
        "We'll follow the steps in section 7.4 of the book.\n",
        "\n",
        "Work through the cells below, running each cell in turn. In various places you will see the words \"TO DO\" or incomplete\n",
        "lines that end with `...`. Follow the instructions at these places and make predictions about what is going to happen or write code to complete the functions."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BOLr-R3CE1C9"
      },
      "source": [
        "### Completing the notebook on Colab\n",
        "\n",
        "To complete the notebook on Colab, you can click on the \"Open in Colab\" button\n",
        "below and it will open the notebook from our public class notebook repository\n",
        "on GitHub.\n",
        "\n",
        "> Note that you will have save the notebook to your own Google Drive by clicking\n",
        "on File -> Save a Copy in Drive.\n",
        "\n",
        "> Also note that the Otter Grader cells will not run in Colab, but you can just\n",
        "> avoid executing those cells. For any public tests, you can submit to Gradescope\n",
        "> and inspect your results there.\n",
        "\n",
        "<a href=\"https://colab.research.google.com/github/DL4DS/sp2025_homeworks/blob/main/hw4/hw4_backpropagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "TGZxubX6E1C9"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "## Statement of AI Use and Correction Reflection (if applicable)\n",
        "\n",
        "You may use ChatGPT/Generative AI as a resource to help you complete the assignment.\n",
        "However, it must be used constructively to help you understand things you are\n",
        "unsure of, and be built upon with original code.\n",
        "\n",
        "You must cite your interaction\n",
        "by describing your prompt and the corresponding response.\n",
        "In addition, you must  explain all code from the AI that you implement in your\n",
        "assignment with inline comments.\n",
        "Touch upon how the code works and how it helped you. Failure to do\n",
        "so could result in credit deduction.\n",
        "\n",
        "The official GAIA Policy can be found here: https://www.bu.edu/cds-faculty/culture-community/gaia-policy/\n",
        "\n",
        "Moreover, if this is a correction submission after the initial submission,\n",
        "you must provide a reflection on what you learned from the initial submission\n",
        "and how you corrected it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-VpR7gJHE1C-"
      },
      "source": [
        "_Type your answer here, replacing this text._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "XzPFyi7hE1C-"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LdIDglk1FFcG"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_SV6PedJE1C_"
      },
      "source": [
        "## Define a simple network\n",
        "\n",
        "Define the number of hidden layers, neurons per layer, input layer, and output layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WVM4Tc_jGI0Q"
      },
      "outputs": [],
      "source": [
        "# Number of hidden layers\n",
        "K = 5\n",
        "\n",
        "# Number of neurons per layer\n",
        "D = 6\n",
        "\n",
        "# Input layer\n",
        "D_i = 1\n",
        "\n",
        "# Output layer\n",
        "D_o = 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nnUoI0m6GyjC"
      },
      "source": [
        "Create all the weight matrices and bias vectors for the dimensions we defined,\n",
        "initialized with random (normally distributed) numbers."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Set seed so we always get the same random numbers\n",
        "np.random.seed(0)\n"
      ],
      "metadata": {
        "id": "xO8Ov6ljE4R6"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "p2DQgN2CE1C_"
      },
      "outputs": [],
      "source": [
        "#   Create a network with K hidden layers, D neurons per layer, D_i input neurons,\n",
        "#  and D_o output neurons. Normalize the weights and biases to be standard normal.\n",
        "\n",
        "def create_network(K, D, D_i, D_o):\n",
        "  # Make empty lists\n",
        "  all_weights = [None] * (K+1)\n",
        "  all_biases = [None] * (K+1)\n",
        "\n",
        "  # Create input and output layers\n",
        "  all_weights[0] = np.random.normal(size=(D, D_i))\n",
        "  all_weights[-1] = np.random.normal(size=(D_o, D))\n",
        "  all_biases[0] = np.random.normal(size =(D,1))\n",
        "  all_biases[-1]= np.random.normal(size =(D_o,1))\n",
        "\n",
        "  # Create intermediate layers\n",
        "  for layer in range(1,K):\n",
        "    all_weights[layer] = np.random.normal(size=(D,D))\n",
        "    all_biases[layer] = np.random.normal(size=(D,1))\n",
        "\n",
        "  return all_weights, all_biases\n",
        "\n",
        "all_weights, all_biases = create_network(K, D, D_i, D_o)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9jkwE9nE1DA"
      },
      "source": [
        "We can print out the shapes of the weights and biases for each layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6YHikGhE1DA",
        "outputId": "767e2497-59e9-4534-c58a-cb32961ce739"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer shapes:\n",
            "Layer 0: weights shape = (6, 1), biases shape = (6, 1)\n",
            "Layer 1: weights shape = (6, 6), biases shape = (6, 1)\n",
            "Layer 2: weights shape = (6, 6), biases shape = (6, 1)\n",
            "Layer 3: weights shape = (6, 6), biases shape = (6, 1)\n",
            "Layer 4: weights shape = (6, 6), biases shape = (6, 1)\n",
            "Layer 5: weights shape = (1, 6), biases shape = (1, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"Layer shapes:\")\n",
        "for i, (weights, biases) in enumerate(zip(all_weights, all_biases)):\n",
        "    print(f\"Layer {i}: weights shape = {weights.shape}, biases shape = {biases.shape}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "jZh-7bPXIDq4"
      },
      "outputs": [],
      "source": [
        "# Define the Rectified Linear Unit (ReLU) function\n",
        "def ReLU(preactivation: np.ndarray) -> np.ndarray:\n",
        "  activation = preactivation.clip(0.0)\n",
        "  return activation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5irtyxnLJSGX"
      },
      "source": [
        "Now let's complete the forward pass function for our random network and run it.\n",
        "\n",
        "The weight matrices $\\boldsymbol\\Omega_{0\\ldots K}$ are the entries of the list \"all_weights\" and the biases $\\boldsymbol\\beta_{0\\ldots K}$ are the entries of the list \"all_biases\"\n",
        "\n",
        "We know that we will need the preactivations $\\mathbf{f}_{0\\ldots K}$ and the activations $\\mathbf{h}_{1\\ldots K}$ for the forward pass of backpropagation, so we'll store and return these as well.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "{Backpropagation Algorithm}\n",
        "\n",
        "Now we repeat this process for a three-layer network (figure 7.1). The intuition and much of the algebra are identical. The main differences are that intermediate variables $\\mathbf{f}_k, \\mathbf{h}_k$ are vectors, the biases $\\boldsymbol{\\beta}_k$ are vectors, the weights $\\boldsymbol{\\Omega}_k$ are matrices, and we are using ReLU functions rather than simple algebraic functions like $\\cos[\\bullet]$.\n",
        "\n",
        "{Forward Pass}\n",
        "We write the network as a series of sequential calculations:\n",
        "\n",
        "$$ \\mathbf{f}_0 = \\boldsymbol{\\beta}_0 + \\boldsymbol{\\Omega}_0 \\mathbf{x}_i $$\n",
        "\n",
        "$$    \\mathbf{h}_1 = a[\\mathbf{f}_0] $$\n",
        "\n",
        "$$    \\mathbf{f}_1 = \\boldsymbol{\\beta}_1 + \\boldsymbol{\\Omega}_1 \\mathbf{h}_1 $$\n",
        "\n",
        "$$    \\mathbf{h}_2 = a[\\mathbf{f}_1] $$\n",
        "\n",
        "$$    \\mathbf{f}_2 = \\boldsymbol{\\beta}_2 + \\boldsymbol{\\Omega}_2 \\mathbf{h}_2 $$\n",
        "\n",
        "$$    \\mathbf{h}_3 = a[\\mathbf{f}_2] $$\n",
        "\n",
        "$$    \\mathbf{f}_3 = \\boldsymbol{\\beta}_3 + \\boldsymbol{\\Omega}_3 \\mathbf{h}_3 $$\n",
        "\n",
        "$$    \\ell_i = l[\\mathbf{f}_3, y_i] $$\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "y6Qkdzs0YZBP"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zkTJGy8lE1DA"
      },
      "source": [
        "### 4.1 Complete the code below to implement the forward pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "LgquJUJvJPaN",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Compute the forward pass of the network.\n",
        "# The input, net_input, is a matrix of shape (D_i, N) where N is the number of samples,\n",
        "# which means that when N>1, we'll get N output samples from the network as well.\n",
        "# We also return the preactivations and activations at each layer as lists of matrices.\n",
        "# We also return the preactivations and activations at each layer as lists of matrices.\n",
        "\n",
        "def forward_pass(net_input, all_weights, all_biases):\n",
        "\n",
        "  # Retrieve number of layers\n",
        "  K = len(all_weights) -1\n",
        "\n",
        "  # We'll store the pre-activations at each layer in a list \"all_f\"\n",
        "  # and the activations in a second list \"all_h\".\n",
        "  all_f = [None] * (K+1)\n",
        "  all_h = [None] * (K+1)\n",
        "\n",
        "  #For convenience, we'll set\n",
        "  # all_h[0] to be the input, and all_f[K] will be the output\n",
        "  all_h[0] = net_input\n",
        "\n",
        "  # Run through the layers, calculating all_f[0...K-1] and all_h[1...K]\n",
        "  for layer in range(K):\n",
        "      # Update preactivations and activations at this layer according to eqn 7.17\n",
        "      # Remember to use np.matmul for matrix multiplications\n",
        "      # TODO -- Complete the lines below\n",
        "      all_f[layer] = np.matmul(all_weights[layer], all_h[layer]) + all_biases[layer]\n",
        "      all_h[layer+1] = ReLU(all_f[layer])\n",
        "\n",
        "  # Compute the output from the last hidden layer\n",
        "  # TODO -- Complete the line below\n",
        "  all_f[K] = np.matmul(all_weights[K], all_h[K]) + all_biases[K]\n",
        "\n",
        "  # Retrieve the output\n",
        "  net_output = all_f[K]\n",
        "\n",
        "  return net_output, all_f, all_h\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "tags": [],
        "id": "7udUwjW9E1DA"
      },
      "outputs": [],
      "source": [
        "# Define input\n",
        "net_input = np.ones((D_i,1)) * 1.2\n",
        "\n",
        "# Compute network output\n",
        "net_output, all_f, all_h = forward_pass(net_input,all_weights, all_biases)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R9MlWyCQE1DB",
        "outputId": "ac7313ca-f943-4946-a2c1-20305d95bdd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Preactivation and activation shapes:\n",
            "h_0 shape = (1, 1)\n",
            "\n",
            "f_0 shape = (6, 1) \n",
            "h_1 shape = (6, 1)\n",
            "\n",
            "f_1 shape = (6, 1) \n",
            "h_2 shape = (6, 1)\n",
            "\n",
            "f_2 shape = (6, 1) \n",
            "h_3 shape = (6, 1)\n",
            "\n",
            "f_3 shape = (6, 1) \n",
            "h_4 shape = (6, 1)\n",
            "\n",
            "f_4 shape = (6, 1) \n",
            "h_5 shape = (6, 1)\n",
            "\n",
            "f_5 shape = (1, 1) \n"
          ]
        }
      ],
      "source": [
        "print(\"Preactivation and activation shapes:\")\n",
        "\n",
        "def print_activations(all_f, all_h):\n",
        "    for i, (f, h) in enumerate(zip(all_f, all_h)):\n",
        "        if i == 0:\n",
        "            print(f\"h_0 shape = {h.shape}\\n\")\n",
        "            print(f\"f_0 shape = {f.shape}\", end=\" \")\n",
        "        else:\n",
        "            print(f\"h_{i} shape = {h.shape}\\n\")\n",
        "            print(f\"f_{i} shape = {f.shape}\", end=\" \")\n",
        "        print()\n",
        "\n",
        "print_activations(all_f, all_h)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "tags": [],
        "id": "4RFdNejwE1DB"
      },
      "outputs": [],
      "source": [
        "# Define input\n",
        "net_input = np.ones((D_i,1)) * 1.2\n",
        "\n",
        "# Compute network output\n",
        "net_output, all_f, all_h = forward_pass(net_input,all_weights, all_biases)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "r4zCTubWE1DB"
      },
      "outputs": [],
      "source": [
        "grader.check(\"q1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SxVTKp3IcoBF"
      },
      "source": [
        "Now let's define a loss function.  We'll just use the least squares loss function. We'll also write a function to compute\n",
        "$\\partial l / \\partial \\mathbf{f}_K$, e.g. the derivative of the loss with respect to the output of the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GCXX9RDsE1DB",
        "outputId": "689897bb-fd9d-47bd-843d-f4486a44c68f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "net_input.shape (1, 1)\n",
            "net_output [[1.906605]]\n"
          ]
        }
      ],
      "source": [
        "# Initalize the network again\n",
        "\n",
        "# Set seed so we always get the same random numbers\n",
        "np.random.seed(0)\n",
        "\n",
        "# Define network dimensions back to 1-D input\n",
        "K = 5; D = 6; D_i = 1; D_o = 1\n",
        "\n",
        "# Create and initialize the network\n",
        "all_weights, all_biases = create_network(K, D, D_i, D_o)\n",
        "\n",
        "# Define input\n",
        "net_input = np.ones((D_i,1)) * 1.2\n",
        "print(\"net_input.shape\", net_input.shape)\n",
        "\n",
        "# Compute the forward pass\n",
        "net_output, all_f, all_h = forward_pass(net_input,all_weights, all_biases)\n",
        "print(\"net_output\", net_output)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "6XqWSYWJdhQR"
      },
      "outputs": [],
      "source": [
        "def least_squares_loss(net_output: np.ndarray, y: np.ndarray) -> float:\n",
        "  return np.sum((net_output-y) * (net_output-y))\n",
        "\n",
        "def d_loss_d_output(net_output, y):\n",
        "    return 2*(net_output - y);\n",
        ""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "njF2DUQmfttR",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "707218b6-bde1-4bef-b436-cf39e033c4a0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "y = [[20.]] Loss = 327.371\n"
          ]
        }
      ],
      "source": [
        "y = np.ones((D_o,1)) * 20.0\n",
        "loss = least_squares_loss(net_output, y)\n",
        "print(f\"y = {y} Loss = {loss:.3f}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "98WmyqFYWA-0"
      },
      "source": [
        "Now let's compute the derivatives of the network.  We already computed the forward pass.  Let's compute the backward pass."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "diDk65jRE1DB"
      },
      "source": [
        "### 4.2 Complete the code below to implement the backward pass"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "{Backpropagation Equations}\n",
        "\n",
        "We can express the backpropagation equations as follows:\n",
        "\n",
        "{Equation 7.22: Derivative of Loss with Respect to Biases}\n",
        "\n",
        "The derivative of the loss with respect to the bias at layer $k$ is:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial \\boldsymbol{\\beta}_k} = \\frac{\\partial L}{\\partial f_k}\n",
        "$$\n",
        "\n",
        "{Equation 7.23: Derivative of Loss with Respect to Weights}\n",
        "\n",
        "The derivative of the loss with respect to the weights at layer \\(k\\) is:\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial \\boldsymbol{\\Omega}_k} = \\frac{\\partial L}{\\partial f_k} \\cdot \\frac{\\partial f_k}{\\partial \\boldsymbol{\\Omega}_k} = \\frac{\\partial L}{\\partial f_k} \\cdot \\mathbf{h}_{k}^T\n",
        "$$\n",
        "\n",
        "{Equation 7.25: Derivative of Loss with Respect to Activations}\n",
        "The derivative of the loss with respect to the activations at layer \\(k\\) is:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial \\mathbf{h}_k} = \\frac{\\partial L}{\\partial f_k} \\cdot \\frac{\\partial f_k}{\\partial \\mathbf{h}_k} = \\boldsymbol{\\Omega}_k^T \\cdot \\frac{\\partial L}{\\partial f_k}\n",
        "$$\n",
        "\n",
        "For the non-output layers, we compute the gradient of the loss with respect to the pre-activation $f_k$:\n",
        "\n",
        "$$\n",
        "\\frac{\\partial L}{\\partial f_k} = I[{f_k}>0] \\times \\frac{\\partial L}{\\partial \\mathbf{h}_k}\n",
        "$$\n",
        "\n",
        "where \\(I{f_k}\\) is the indicator function of the ReLU derivative:\n",
        "$$\n",
        "I{f_k} =\n",
        "\\begin{cases}\n",
        "1 & \\text{if } f_k > 0 \\\\\n",
        "0 & \\text{if } f_k \\leq 0\n",
        "\\end{cases}\n",
        "$$\n",
        "\n"
      ],
      "metadata": {
        "id": "FFXuYubmh4ge"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# We'll need the indicator function\n",
        "def indicator_function(x):\n",
        "  x_in = np.array(x)\n",
        "  x_in[x_in>0] = 1\n",
        "  x_in[x_in<=0] = 0\n",
        "  return x_in\n",
        ""
      ],
      "metadata": {
        "id": "Ud6vsPcwbn9Z"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "LJng7WpRPLMz",
        "tags": []
      },
      "outputs": [],
      "source": [
        "# Main backward pass routine\n",
        "def backward_pass(all_weights, all_biases, all_f, all_h, y):\n",
        "\n",
        "  # Retrieve number of layers\n",
        "  K = len(all_weights) -1\n",
        "\n",
        "  # We'll store the derivatives dl_dweights and dl_dbiases in lists as well\n",
        "  all_dl_dweights = [None] * (K+1)\n",
        "  all_dl_dbiases = [None] * (K+1)\n",
        "\n",
        "  # And we'll store the derivatives of the loss with respect to the activation and preactivations in lists\n",
        "  all_dl_df = [None] * (K+1)\n",
        "  all_dl_dh = [None] * (K+1)\n",
        "\n",
        "  # Again for convenience we'll stick with the convention that all_h[0] is the net input and all_f[k] in the net output\n",
        "\n",
        "  # Compute derivatives of the loss with respect to the network output\n",
        "  all_dl_df[K] = np.array(d_loss_d_output(all_f[K],y))\n",
        "\n",
        "  # Now work backwards through the network, Follow from equations 7.22 onwards\n",
        "  for layer in range(K,-1,-1):\n",
        "\n",
        "    # TODO Calculate the derivatives of the loss with respect to the biases at layer from all_dl_df[layer]. (eq 7.22)\n",
        "    # NOTE!  To take a copy of matrix X, use Z=np.array(X)\n",
        "    # COMPLETE THIS LINE\n",
        "\n",
        "    all_dl_dbiases[layer] = all_dl_df[layer]\n",
        "\n",
        "    # TODO Calculate the derivatives of the loss with respect to the weights at layer from all_dl_df[layer] and\n",
        "    # all_h[layer] (eq 7.23)\n",
        "    # Don't forget to use np.matmul\n",
        "    # COMPLETE THIS LINE\n",
        "\n",
        "    all_dl_dweights[layer] = np.matmul(all_dl_df[layer], all_h[layer].T)\n",
        "\n",
        "    # TODO: calculate the derivatives of the loss with respect to the activations from weight and derivatives of next\n",
        "    # preactivations (second part of last line of eq 7.25)\n",
        "    # COMPLETE THIS LINE\n",
        "\n",
        "    all_dl_dh[layer] = np.matmul(all_weights[layer].T, all_dl_df[layer])\n",
        "\n",
        "\n",
        "    if layer > 0:\n",
        "      # TODO Calculate the derivatives of the loss with respect to the pre-activation f (use derivative of ReLu function,\n",
        "      # first part of last line of eq. 7.25)\n",
        "      # COMPLETE THIS LINE\n",
        "\n",
        "      all_dl_df[layer-1] = np.multiply(all_dl_dh[layer], indicator_function(all_f[layer-1]))\n",
        "\n",
        "  return all_dl_dweights, all_dl_dbiases\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "9A9MHc4sQvbp",
        "tags": []
      },
      "outputs": [],
      "source": [
        "all_dl_dweights, all_dl_dbiases = backward_pass(all_weights, all_biases, all_f, all_h, y)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_dl_dweights\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GAuEMcrxmEoW",
        "outputId": "2ceaf29f-ce56-4afc-e728-13a562cfe5f2"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ -5.38313851],\n",
              "        [  5.93693359],\n",
              "        [  8.1738345 ],\n",
              "        [ -4.66015537],\n",
              "        [-29.92232006],\n",
              "        [  0.        ]]),\n",
              " array([[  0.        ,   0.        ,   0.        ,   0.        ,\n",
              "           0.        ,   0.        ],\n",
              "        [-32.51134334,  -6.7991913 , -18.28231837, -34.14764932,\n",
              "         -42.19558628,   0.        ],\n",
              "        [  0.        ,   0.        ,   0.        ,   0.        ,\n",
              "           0.        ,   0.        ],\n",
              "        [  0.        ,   0.        ,   0.        ,   0.        ,\n",
              "           0.        ,   0.        ],\n",
              "        [-30.85618994,  -6.45304428, -17.35156504, -32.40919155,\n",
              "         -40.04740781,   0.        ],\n",
              "        [  0.        ,   0.        ,   0.        ,   0.        ,\n",
              "           0.        ,   0.        ]]),\n",
              " array([[  0.        ,   0.        ,   0.        ,   0.        ,\n",
              "           0.        ,   0.        ],\n",
              "        [  0.        ,   0.        ,   0.        ,   0.        ,\n",
              "           0.        ,   0.        ],\n",
              "        [  0.        ,   5.37135622,   0.        ,   0.        ,\n",
              "           3.14460048,   0.        ],\n",
              "        [  0.        ,   0.        ,   0.        ,   0.        ,\n",
              "           0.        ,   0.        ],\n",
              "        [  0.        , -57.23278199,   0.        ,   0.        ,\n",
              "         -33.50629267,   0.        ],\n",
              "        [  0.        ,   2.90687606,   0.        ,   0.        ,\n",
              "           1.7017981 ,   0.        ]]),\n",
              " array([[  0.        ,   0.        ,   0.        ,   0.        ,\n",
              "           0.        ,   0.        ],\n",
              "        [  0.        ,   0.        ,  -3.67404472,   0.        ,\n",
              "         -42.90504609, -10.99843475],\n",
              "        [  0.        ,   0.        ,  -1.27166035,   0.        ,\n",
              "         -14.85029441,  -3.8067782 ],\n",
              "        [  0.        ,   0.        ,   0.        ,   0.        ,\n",
              "           0.        ,   0.        ],\n",
              "        [  0.        ,   0.        ,   2.59746346,   0.        ,\n",
              "          30.33286142,   7.77563544],\n",
              "        [  0.        ,   0.        ,   4.12642455,   0.        ,\n",
              "          48.1878825 ,  12.35265615]]),\n",
              " array([[  0.        ,   0.        ,   0.        ,   0.        ,\n",
              "           0.        ,   0.        ],\n",
              "        [  0.        ,   0.        ,   0.        ,   0.        ,\n",
              "           0.        ,   0.        ],\n",
              "        [  0.        ,   0.        ,   0.        ,   0.        ,\n",
              "           0.        ,   0.        ],\n",
              "        [  0.        ,   0.        ,   0.        ,   0.        ,\n",
              "           0.        ,   0.        ],\n",
              "        [  0.        , -81.63541187, -49.13560664,   0.        ,\n",
              "         -22.00669771, -10.14554606],\n",
              "        [  0.        ,   0.        ,   0.        ,   0.        ,\n",
              "           0.        ,   0.        ]]),\n",
              " array([[   0.        ,    0.        ,    0.        ,    0.        ,\n",
              "         -400.33025447,    0.        ]])]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "all_dl_dbiases\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UbPlixDPmKue",
        "outputId": "bf887341-dd58-4618-96be-4a1bab15e8af"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[array([[ -4.48594876],\n",
              "        [  4.94744466],\n",
              "        [  6.81152875],\n",
              "        [ -3.88346281],\n",
              "        [-24.93526672],\n",
              "        [  0.        ]]),\n",
              " array([[ -0.        ],\n",
              "        [-11.29689608],\n",
              "        [  0.        ],\n",
              "        [  0.        ],\n",
              "        [-10.72177079],\n",
              "        [  0.        ]]),\n",
              " array([[-0.        ],\n",
              "        [-0.        ],\n",
              "        [ 0.93788659],\n",
              "        [ 0.        ],\n",
              "        [-9.99335294],\n",
              "        [ 0.50756642]]),\n",
              " array([[-0.        ],\n",
              "        [-4.7999531 ],\n",
              "        [-1.66135975],\n",
              "        [-0.        ],\n",
              "        [ 3.39345428],\n",
              "        [ 5.3909644 ]]),\n",
              " array([[-0.        ],\n",
              "        [ 0.        ],\n",
              "        [ 0.        ],\n",
              "        [-0.        ],\n",
              "        [-5.21247446],\n",
              "        [-0.        ]]),\n",
              " array([[-36.18679]])]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "np.set_printoptions(precision=3)\n",
        "# Make space for derivatives computed by finite differences\n",
        "all_dl_dweights_fd = [None] * (K+1)\n",
        "all_dl_dbiases_fd = [None] * (K+1)\n",
        "\n",
        "# Let's test if we have the derivatives right using finite differences\n",
        "delta_fd = 0.000001\n"
      ],
      "metadata": {
        "id": "1KSgqoFdfKB7"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test the dervatives of the bias vectors\n",
        "for layer in range(K+1):\n",
        "  dl_dbias  = np.zeros_like(all_dl_dbiases[layer])\n",
        "  # For every element in the bias\n",
        "  for row in range(all_biases[layer].shape[0]):\n",
        "    # Take copy of biases  We'll change one element each time\n",
        "    all_biases_copy = [np.array(x) for x in all_biases]\n",
        "    all_biases_copy[layer][row] += delta_fd\n",
        "    network_output_1, *_ = forward_pass(net_input, all_weights, all_biases_copy)\n",
        "    network_output_2, *_ = forward_pass(net_input, all_weights, all_biases)\n",
        "    dl_dbias[row] = (least_squares_loss(network_output_1, y) - least_squares_loss(network_output_2,y))/delta_fd\n",
        "  all_dl_dbiases_fd[layer] = np.array(dl_dbias)\n",
        "  print(\"-----------------------------------------------\")\n",
        "  print(\"Bias %d, derivatives from backprop:\"%(layer))\n",
        "  print(all_dl_dbiases[layer])\n",
        "  print(\"Bias %d, derivatives from finite differences\"%(layer))\n",
        "  print(all_dl_dbiases_fd[layer])\n",
        "  assert np.allclose(all_dl_dbiases_fd[layer],all_dl_dbiases[layer],rtol=1e-05, atol=1e-08, equal_nan=False), \"Derivatives do not match\"\n",
        "  if np.allclose(all_dl_dbiases_fd[layer],all_dl_dbiases[layer],rtol=1e-05, atol=1e-08, equal_nan=False):\n",
        "    print(\"Success!  Derivatives match.\")\n",
        "  else:\n",
        "    print(\"Failure!  Derivatives different.\")\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D1B3K3x2fNEg",
        "outputId": "8f91fd29-fdd4-456a-c9b2-daadd51f65c6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------\n",
            "Bias 0, derivatives from backprop:\n",
            "[[ -4.486]\n",
            " [  4.947]\n",
            " [  6.812]\n",
            " [ -3.883]\n",
            " [-24.935]\n",
            " [  0.   ]]\n",
            "Bias 0, derivatives from finite differences\n",
            "[[ -4.486]\n",
            " [  4.947]\n",
            " [  6.812]\n",
            " [ -3.883]\n",
            " [-24.935]\n",
            " [  0.   ]]\n",
            "Success!  Derivatives match.\n",
            "-----------------------------------------------\n",
            "Bias 1, derivatives from backprop:\n",
            "[[ -0.   ]\n",
            " [-11.297]\n",
            " [  0.   ]\n",
            " [  0.   ]\n",
            " [-10.722]\n",
            " [  0.   ]]\n",
            "Bias 1, derivatives from finite differences\n",
            "[[  0.   ]\n",
            " [-11.297]\n",
            " [  0.   ]\n",
            " [  0.   ]\n",
            " [-10.722]\n",
            " [  0.   ]]\n",
            "Success!  Derivatives match.\n",
            "-----------------------------------------------\n",
            "Bias 2, derivatives from backprop:\n",
            "[[-0.   ]\n",
            " [-0.   ]\n",
            " [ 0.938]\n",
            " [ 0.   ]\n",
            " [-9.993]\n",
            " [ 0.508]]\n",
            "Bias 2, derivatives from finite differences\n",
            "[[ 0.   ]\n",
            " [ 0.   ]\n",
            " [ 0.938]\n",
            " [ 0.   ]\n",
            " [-9.993]\n",
            " [ 0.508]]\n",
            "Success!  Derivatives match.\n",
            "-----------------------------------------------\n",
            "Bias 3, derivatives from backprop:\n",
            "[[-0.   ]\n",
            " [-4.8  ]\n",
            " [-1.661]\n",
            " [-0.   ]\n",
            " [ 3.393]\n",
            " [ 5.391]]\n",
            "Bias 3, derivatives from finite differences\n",
            "[[ 0.   ]\n",
            " [-4.8  ]\n",
            " [-1.661]\n",
            " [ 0.   ]\n",
            " [ 3.393]\n",
            " [ 5.391]]\n",
            "Success!  Derivatives match.\n",
            "-----------------------------------------------\n",
            "Bias 4, derivatives from backprop:\n",
            "[[-0.   ]\n",
            " [ 0.   ]\n",
            " [ 0.   ]\n",
            " [-0.   ]\n",
            " [-5.212]\n",
            " [-0.   ]]\n",
            "Bias 4, derivatives from finite differences\n",
            "[[ 0.   ]\n",
            " [ 0.   ]\n",
            " [ 0.   ]\n",
            " [ 0.   ]\n",
            " [-5.212]\n",
            " [ 0.   ]]\n",
            "Success!  Derivatives match.\n",
            "-----------------------------------------------\n",
            "Bias 5, derivatives from backprop:\n",
            "[[-36.187]]\n",
            "Bias 5, derivatives from finite differences\n",
            "[[-36.187]]\n",
            "Success!  Derivatives match.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "PK-UtE3hreAK",
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "860302bf-a6c9-4d76-f53f-f4c839a645e2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "-----------------------------------------------\n",
            "Weight 0, derivatives from backprop:\n",
            "[[ -5.383]\n",
            " [  5.937]\n",
            " [  8.174]\n",
            " [ -4.66 ]\n",
            " [-29.922]\n",
            " [  0.   ]]\n",
            "Weight 0, derivatives from finite differences\n",
            "[[ -5.383]\n",
            " [  5.937]\n",
            " [  8.174]\n",
            " [ -4.66 ]\n",
            " [-29.922]\n",
            " [  0.   ]]\n",
            "Success!  Derivatives match.\n",
            "-----------------------------------------------\n",
            "Weight 1, derivatives from backprop:\n",
            "[[  0.      0.      0.      0.      0.      0.   ]\n",
            " [-32.511  -6.799 -18.282 -34.148 -42.196   0.   ]\n",
            " [  0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.      0.      0.      0.      0.      0.   ]\n",
            " [-30.856  -6.453 -17.352 -32.409 -40.047   0.   ]\n",
            " [  0.      0.      0.      0.      0.      0.   ]]\n",
            "Weight 1, derivatives from finite differences\n",
            "[[  0.      0.      0.      0.      0.      0.   ]\n",
            " [-32.511  -6.799 -18.282 -34.148 -42.196   0.   ]\n",
            " [  0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.      0.      0.      0.      0.      0.   ]\n",
            " [-30.856  -6.453 -17.352 -32.409 -40.047   0.   ]\n",
            " [  0.      0.      0.      0.      0.      0.   ]]\n",
            "Success!  Derivatives match.\n",
            "-----------------------------------------------\n",
            "Weight 2, derivatives from backprop:\n",
            "[[  0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.      5.371   0.      0.      3.145   0.   ]\n",
            " [  0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.    -57.233   0.      0.    -33.506   0.   ]\n",
            " [  0.      2.907   0.      0.      1.702   0.   ]]\n",
            "Weight 2, derivatives from finite differences\n",
            "[[  0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.      5.371   0.      0.      3.145   0.   ]\n",
            " [  0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.    -57.233   0.      0.    -33.506   0.   ]\n",
            " [  0.      2.907   0.      0.      1.702   0.   ]]\n",
            "Success!  Derivatives match.\n",
            "-----------------------------------------------\n",
            "Weight 3, derivatives from backprop:\n",
            "[[  0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.      0.     -3.674   0.    -42.905 -10.998]\n",
            " [  0.      0.     -1.272   0.    -14.85   -3.807]\n",
            " [  0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.      0.      2.597   0.     30.333   7.776]\n",
            " [  0.      0.      4.126   0.     48.188  12.353]]\n",
            "Weight 3, derivatives from finite differences\n",
            "[[  0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.      0.     -3.674   0.    -42.905 -10.998]\n",
            " [  0.      0.     -1.272   0.    -14.85   -3.807]\n",
            " [  0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.      0.      2.597   0.     30.333   7.776]\n",
            " [  0.      0.      4.126   0.     48.188  12.353]]\n",
            "Success!  Derivatives match.\n",
            "-----------------------------------------------\n",
            "Weight 4, derivatives from backprop:\n",
            "[[  0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.    -81.635 -49.136   0.    -22.007 -10.146]\n",
            " [  0.      0.      0.      0.      0.      0.   ]]\n",
            "Weight 4, derivatives from finite differences\n",
            "[[  0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.      0.      0.      0.      0.      0.   ]\n",
            " [  0.    -81.635 -49.136   0.    -22.007 -10.146]\n",
            " [  0.      0.      0.      0.      0.      0.   ]]\n",
            "Success!  Derivatives match.\n",
            "-----------------------------------------------\n",
            "Weight 5, derivatives from backprop:\n",
            "[[   0.      0.      0.      0.   -400.33    0.  ]]\n",
            "Weight 5, derivatives from finite differences\n",
            "[[   0.      0.      0.      0.   -400.33    0.  ]]\n",
            "Success!  Derivatives match.\n"
          ]
        }
      ],
      "source": [
        "# Test the derivatives of the weights matrices\n",
        "for layer in range(K+1):\n",
        "  dl_dweight  = np.zeros_like(all_dl_dweights[layer])\n",
        "  # For every element in the bias\n",
        "  for row in range(all_weights[layer].shape[0]):\n",
        "    for col in range(all_weights[layer].shape[1]):\n",
        "      # Take copy of biases  We'll change one element each time\n",
        "      all_weights_copy = [np.array(x) for x in all_weights]\n",
        "      all_weights_copy[layer][row][col] += delta_fd\n",
        "      network_output_1, *_ = forward_pass(net_input, all_weights_copy, all_biases)\n",
        "      network_output_2, *_ = forward_pass(net_input, all_weights, all_biases)\n",
        "      dl_dweight[row][col] = (least_squares_loss(network_output_1, y) - least_squares_loss(network_output_2,y))/delta_fd\n",
        "  all_dl_dweights_fd[layer] = np.array(dl_dweight)\n",
        "  print(\"-----------------------------------------------\")\n",
        "  print(\"Weight %d, derivatives from backprop:\"%(layer))\n",
        "  print(all_dl_dweights[layer])\n",
        "  print(\"Weight %d, derivatives from finite differences\"%(layer))\n",
        "  print(all_dl_dweights_fd[layer])\n",
        "\n",
        "  assert np.allclose(all_dl_dweights_fd[layer],all_dl_dweights[layer],rtol=1e-05, atol=1e-08, equal_nan=False), \"Derivatives do not match\"\n",
        "  if np.allclose(all_dl_dweights_fd[layer],all_dl_dweights[layer],rtol=1e-05, atol=1e-08, equal_nan=False):\n",
        "    print(\"Success!  Derivatives match.\")\n",
        "  else:\n",
        "    print(\"Failure!  Derivatives different.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "0oCKcvE4E1DC"
      },
      "outputs": [],
      "source": [
        "grader.check(\"q2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pFrqXuYWE1DC"
      },
      "source": [
        "## Training the Network\n",
        "\n",
        "Now we have all the pieces we need to implement a training loop. We'll define\n",
        "a trivial data set of 4 samples, and then construct a training loop and run it."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qoV85qpSE1DC"
      },
      "source": [
        "### Create dataset\n",
        "\n",
        "Define our training set to be 4 samples, 3 dimensional input, and 1 dimensional output."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qul7YE3WE1DC",
        "outputId": "572d8400-022d-4041-d2a1-7b4395452e55"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "net_input [[ 2.   3.   0.5  1. ]\n",
            " [ 3.  -1.   1.   1. ]\n",
            " [-1.   0.5  1.  -1. ]]\n",
            "net_input.shape (3, 4)\n",
            "y [1. 0. 0. 1.]\n",
            "y.shape (4,)\n"
          ]
        }
      ],
      "source": [
        "net_input = np.array([\n",
        "        [2.0, 3.0, -1.0],\n",
        "        [3.0, -1.0, 0.5],\n",
        "        [0.5, 1.0, 1.0],\n",
        "        [1.0, 1.0, -1.0]\n",
        "    ])\n",
        "net_input = net_input.T\n",
        "print(\"net_input\", net_input)\n",
        "print(\"net_input.shape\", net_input.shape)\n",
        "\n",
        "y = np.array([1.0, 0.0, 0.0, 1.0])\n",
        "print(\"y\", y)\n",
        "print(\"y.shape\", y.shape)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oOhmVam_E1DC"
      },
      "source": [
        "### Define and initialize the network\n",
        "\n",
        "Define the dimensions of the network."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "-ff8G1rdE1DC"
      },
      "outputs": [],
      "source": [
        "# Number of hidden layers\n",
        "K = 5\n",
        "# Number of neurons per layer\n",
        "D = 6\n",
        "# Input layer\n",
        "D_i = 3\n",
        "# Output layer\n",
        "D_o = 1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yQO3TRrTE1DC"
      },
      "source": [
        "Define and initialize the appropriate number of weights and biases for each layer.\n",
        "\n",
        "We randomly initialize each to a standard normal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "TYzN0hxvE1DC"
      },
      "outputs": [],
      "source": [
        "# Set seed so we always get the same random numbers\n",
        "np.random.seed(0)\n",
        "\n",
        "all_weights, all_biases = create_network(K, D, D_i, D_o)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3k36EWRNE1DC"
      },
      "source": [
        "Print the shapes of the weights and biases for each layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BQiQyCJOE1DI",
        "outputId": "5a7fcf2c-4b71-4dd3-e7db-0ec2c75390ee"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer shapes:\n",
            "Layer 0: weights shape = (6, 3), biases shape = (6, 1)\n",
            "Layer 1: weights shape = (6, 6), biases shape = (6, 1)\n",
            "Layer 2: weights shape = (6, 6), biases shape = (6, 1)\n",
            "Layer 3: weights shape = (6, 6), biases shape = (6, 1)\n",
            "Layer 4: weights shape = (6, 6), biases shape = (6, 1)\n",
            "Layer 5: weights shape = (1, 6), biases shape = (1, 1)\n"
          ]
        }
      ],
      "source": [
        "print(\"Layer shapes:\")\n",
        "for i, (weights, biases) in enumerate(zip(all_weights, all_biases)):\n",
        "    print(f\"Layer {i}: weights shape = {weights.shape}, biases shape = {biases.shape}\")\n",
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QUlUIH5E1DI"
      },
      "source": [
        "### Training Loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SCp8WdxWE1DI"
      },
      "source": [
        "We can calculate the forward pass. Because of the broadcasting rules of numpy,\n",
        "we can give all the inputs as one matrix and get the output for all the inputs at once."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3K-t8UnE1DI",
        "outputId": "3e338aa5-e5be-4776-e6a0-e4ae2f17fe5b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 1: Loss = 1209.745\n",
            "Iteration 2: Loss = 53.034\n",
            "Iteration 3: Loss = 0.829\n",
            "Iteration 4: Loss = 0.796\n",
            "Iteration 5: Loss = 0.765\n",
            "Iteration 6: Loss = 0.735\n",
            "Iteration 7: Loss = 0.705\n",
            "Iteration 8: Loss = 0.678\n",
            "Iteration 9: Loss = 0.651\n",
            "Iteration 10: Loss = 0.625\n",
            "Iteration 11: Loss = 0.600\n",
            "Iteration 12: Loss = 0.576\n",
            "Iteration 13: Loss = 0.554\n",
            "Iteration 14: Loss = 0.532\n",
            "Iteration 15: Loss = 0.511\n",
            "Iteration 16: Loss = 0.490\n",
            "Iteration 17: Loss = 0.471\n",
            "Iteration 18: Loss = 0.452\n",
            "Iteration 19: Loss = 0.434\n",
            "Iteration 20: Loss = 0.417\n",
            "Iteration 21: Loss = 0.401\n",
            "Iteration 22: Loss = 0.385\n",
            "Iteration 23: Loss = 0.370\n",
            "Iteration 24: Loss = 0.355\n",
            "Iteration 25: Loss = 0.341\n",
            "Iteration 26: Loss = 0.327\n",
            "Iteration 27: Loss = 0.314\n",
            "Iteration 28: Loss = 0.302\n",
            "Iteration 29: Loss = 0.290\n",
            "Iteration 30: Loss = 0.279\n",
            "Iteration 31: Loss = 0.267\n",
            "Iteration 32: Loss = 0.257\n",
            "Iteration 33: Loss = 0.247\n",
            "Iteration 34: Loss = 0.237\n",
            "Iteration 35: Loss = 0.228\n",
            "Iteration 36: Loss = 0.219\n",
            "Iteration 37: Loss = 0.210\n",
            "Iteration 38: Loss = 0.202\n",
            "Iteration 39: Loss = 0.194\n",
            "Iteration 40: Loss = 0.186\n",
            "Iteration 41: Loss = 0.179\n",
            "Iteration 42: Loss = 0.172\n",
            "Iteration 43: Loss = 0.165\n",
            "Iteration 44: Loss = 0.158\n",
            "Iteration 45: Loss = 0.152\n",
            "Iteration 46: Loss = 0.146\n",
            "Iteration 47: Loss = 0.140\n",
            "Iteration 48: Loss = 0.135\n",
            "Iteration 49: Loss = 0.129\n",
            "Iteration 50: Loss = 0.124\n",
            "Iteration 51: Loss = 0.119\n",
            "Iteration 52: Loss = 0.115\n",
            "Iteration 53: Loss = 0.110\n",
            "Iteration 54: Loss = 0.106\n",
            "Iteration 55: Loss = 0.101\n",
            "Iteration 56: Loss = 0.097\n",
            "Iteration 57: Loss = 0.094\n",
            "Iteration 58: Loss = 0.090\n",
            "Iteration 59: Loss = 0.086\n",
            "Iteration 60: Loss = 0.083\n",
            "Iteration 61: Loss = 0.080\n",
            "Iteration 62: Loss = 0.076\n",
            "Iteration 63: Loss = 0.073\n",
            "Iteration 64: Loss = 0.071\n",
            "Iteration 65: Loss = 0.068\n",
            "Iteration 66: Loss = 0.065\n",
            "Iteration 67: Loss = 0.062\n",
            "Iteration 68: Loss = 0.060\n",
            "Iteration 69: Loss = 0.058\n",
            "Iteration 70: Loss = 0.055\n",
            "Iteration 71: Loss = 0.053\n",
            "Iteration 72: Loss = 0.051\n",
            "Iteration 73: Loss = 0.049\n",
            "Iteration 74: Loss = 0.047\n",
            "Iteration 75: Loss = 0.045\n",
            "Iteration 76: Loss = 0.043\n",
            "Iteration 77: Loss = 0.042\n",
            "Iteration 78: Loss = 0.040\n",
            "Iteration 79: Loss = 0.038\n",
            "Iteration 80: Loss = 0.037\n",
            "Iteration 81: Loss = 0.035\n",
            "Iteration 82: Loss = 0.034\n",
            "Iteration 83: Loss = 0.033\n",
            "Iteration 84: Loss = 0.031\n",
            "Iteration 85: Loss = 0.030\n",
            "Iteration 86: Loss = 0.029\n",
            "Iteration 87: Loss = 0.028\n",
            "Iteration 88: Loss = 0.027\n",
            "Iteration 89: Loss = 0.026\n",
            "Iteration 90: Loss = 0.025\n",
            "Iteration 91: Loss = 0.024\n",
            "Iteration 92: Loss = 0.023\n",
            "Iteration 93: Loss = 0.022\n",
            "Iteration 94: Loss = 0.021\n",
            "Iteration 95: Loss = 0.020\n",
            "Iteration 96: Loss = 0.019\n",
            "Iteration 97: Loss = 0.019\n",
            "Iteration 98: Loss = 0.018\n",
            "Iteration 99: Loss = 0.017\n",
            "Iteration 100: Loss = 0.016\n",
            "Iteration 101: Loss = 0.016\n",
            "Iteration 102: Loss = 0.015\n",
            "Iteration 103: Loss = 0.015\n",
            "Iteration 104: Loss = 0.014\n",
            "Iteration 105: Loss = 0.013\n",
            "Iteration 106: Loss = 0.013\n",
            "Iteration 107: Loss = 0.012\n",
            "Iteration 108: Loss = 0.012\n",
            "Iteration 109: Loss = 0.011\n",
            "Iteration 110: Loss = 0.011\n",
            "Iteration 111: Loss = 0.011\n",
            "Iteration 112: Loss = 0.010\n",
            "Iteration 113: Loss = 0.010\n",
            "Iteration 114: Loss = 0.009\n",
            "Iteration 115: Loss = 0.009\n",
            "Iteration 116: Loss = 0.009\n",
            "Iteration 117: Loss = 0.008\n",
            "Iteration 118: Loss = 0.008\n",
            "Iteration 119: Loss = 0.008\n",
            "Iteration 120: Loss = 0.007\n",
            "Iteration 121: Loss = 0.007\n",
            "Iteration 122: Loss = 0.007\n",
            "Iteration 123: Loss = 0.006\n",
            "Iteration 124: Loss = 0.006\n",
            "Iteration 125: Loss = 0.006\n",
            "Iteration 126: Loss = 0.006\n",
            "Iteration 127: Loss = 0.006\n",
            "Iteration 128: Loss = 0.005\n",
            "Iteration 129: Loss = 0.005\n",
            "Iteration 130: Loss = 0.005\n",
            "Iteration 131: Loss = 0.005\n",
            "Iteration 132: Loss = 0.005\n",
            "Iteration 133: Loss = 0.004\n",
            "Iteration 134: Loss = 0.004\n",
            "Iteration 135: Loss = 0.004\n",
            "Iteration 136: Loss = 0.004\n",
            "Iteration 137: Loss = 0.004\n",
            "Iteration 138: Loss = 0.004\n",
            "Iteration 139: Loss = 0.003\n",
            "Iteration 140: Loss = 0.003\n",
            "Iteration 141: Loss = 0.003\n",
            "Iteration 142: Loss = 0.003\n",
            "Iteration 143: Loss = 0.003\n",
            "Iteration 144: Loss = 0.003\n",
            "Iteration 145: Loss = 0.003\n",
            "Iteration 146: Loss = 0.003\n",
            "Iteration 147: Loss = 0.002\n",
            "Iteration 148: Loss = 0.002\n",
            "Iteration 149: Loss = 0.002\n",
            "Iteration 150: Loss = 0.002\n",
            "Iteration 151: Loss = 0.002\n",
            "Iteration 152: Loss = 0.002\n",
            "Iteration 153: Loss = 0.002\n",
            "Iteration 154: Loss = 0.002\n",
            "Iteration 155: Loss = 0.002\n",
            "Iteration 156: Loss = 0.002\n",
            "Iteration 157: Loss = 0.002\n",
            "Iteration 158: Loss = 0.002\n",
            "Iteration 159: Loss = 0.002\n",
            "Iteration 160: Loss = 0.001\n",
            "Iteration 161: Loss = 0.001\n",
            "Iteration 162: Loss = 0.001\n",
            "Iteration 163: Loss = 0.001\n",
            "Iteration 164: Loss = 0.001\n",
            "Iteration 165: Loss = 0.001\n",
            "Iteration 166: Loss = 0.001\n",
            "Iteration 167: Loss = 0.001\n",
            "Iteration 168: Loss = 0.001\n",
            "Iteration 169: Loss = 0.001\n",
            "Iteration 170: Loss = 0.001\n",
            "Iteration 171: Loss = 0.001\n",
            "Iteration 172: Loss = 0.001\n",
            "Iteration 173: Loss = 0.001\n",
            "Iteration 174: Loss = 0.001\n",
            "Iteration 175: Loss = 0.001\n",
            "Iteration 176: Loss = 0.001\n",
            "Iteration 177: Loss = 0.001\n",
            "Iteration 178: Loss = 0.001\n",
            "Iteration 179: Loss = 0.001\n",
            "Iteration 180: Loss = 0.001\n",
            "Iteration 181: Loss = 0.001\n",
            "Iteration 182: Loss = 0.001\n",
            "Iteration 183: Loss = 0.001\n",
            "Iteration 184: Loss = 0.001\n",
            "Iteration 185: Loss = 0.001\n",
            "Iteration 186: Loss = 0.001\n",
            "Iteration 187: Loss = 0.000\n",
            "Iteration 188: Loss = 0.000\n",
            "Iteration 189: Loss = 0.000\n",
            "Iteration 190: Loss = 0.000\n",
            "Iteration 191: Loss = 0.000\n",
            "Iteration 192: Loss = 0.000\n",
            "Iteration 193: Loss = 0.000\n",
            "Iteration 194: Loss = 0.000\n",
            "Iteration 195: Loss = 0.000\n",
            "Iteration 196: Loss = 0.000\n",
            "Iteration 197: Loss = 0.000\n",
            "Iteration 198: Loss = 0.000\n",
            "Iteration 199: Loss = 0.000\n",
            "Iteration 200: Loss = 0.000\n",
            "[1. 0. 0. 1.]\n",
            "[[ 0.991 -0.008 -0.004  0.988]]\n"
          ]
        }
      ],
      "source": [
        "num_iterations = 200\n",
        "alpha = 0.01   # learning rate\n",
        "\n",
        "losses = []\n",
        "for i in range(num_iterations):\n",
        "    net_output, all_f, all_h = forward_pass(net_input,all_weights, all_biases)\n",
        "    y_pred = net_output\n",
        "    loss = least_squares_loss(y_pred, y)\n",
        "    losses.append(loss)\n",
        "    print(f\"Iteration {i+1}: Loss = {loss:.3f}\")\n",
        "\n",
        "    all_dl_dweights, all_dl_dbiases = backward_pass(all_weights, all_biases, all_f, all_h, y)\n",
        "\n",
        "    for i, (weights, biases) in enumerate(zip(all_weights, all_biases)):\n",
        "        all_weights[i] = weights - alpha * all_dl_dweights[i]\n",
        "        all_biases[i] = biases - alpha * all_dl_dbiases[i]\n",
        "\n",
        "print(y)\n",
        "print(y_pred)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oKrGsHXxE1DI"
      },
      "source": [
        "Let's plot the loss over the iterations.  We'll plot the full loss over the iterations, and then zoom in on the loss from iteration 10 onwards."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 507
        },
        "id": "_S2ijxflE1DI",
        "outputId": "55781599-7928-4f80-ba57-0250d88dcbfb"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x500 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# plot the losses\n",
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
        "\n",
        "# Full plot\n",
        "ax1.plot(losses)\n",
        "ax1.set_xlabel('Iteration')\n",
        "ax1.set_ylabel('Loss')\n",
        "ax1.set_title('Loss over Iterations')\n",
        "\n",
        "# Plot starting from iteration 10\n",
        "ax2.plot(range(10, len(losses)), losses[10:])\n",
        "ax2.set_xlabel('Iteration')\n",
        "ax2.set_ylabel('Loss')\n",
        "ax2.set_title('Loss from Iteration 10')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "4jEstd-hE1DI"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "**Question 3:**\n",
        "\n",
        "What do you notice about how the loss progresses over the iterations? Is it a gradual decrease or a sharp decrease? To what do you attribute the rate of\n",
        "decrease in the first few iterations?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMJxiAtjE1DI"
      },
      "source": [
        "Answer:\n",
        "\n",
        "loss reduction very fast early on, then it tails off and slow down\n",
        "\n",
        "Loss has a very sharp decrease from iteration 0 - 10, the vast majority of loss reduction occur very early on, then the loss decreases very slowly\n",
        "\n",
        "But from iteration 10 on ward, we can see the loss is still decreasing, at a slower rate. from iteration 10 to 25, the reduction is still big.\n",
        "\n",
        "it could be the initialization point is has very high loss, and first few gradient is very big, so we can do downhill on loss curve very fast in the first few iterations. then the gradient gets small, so the loss decreases slowly.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "XRav6KZbE1DI"
      },
      "source": [
        "<!-- END QUESTION -->\n",
        "\n",
        "## Build and Train an Equivalent Network with PyTorch\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4noWOHWE1DJ"
      },
      "source": [
        "For comparison, we'll now define the network in PyTorch and train it with the\n",
        "same tiny dataset. Hopefully you see some similarities in how the network is\n",
        "defined and trained."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import SGD\n"
      ],
      "metadata": {
        "id": "m8W6dNFarFwB"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Manually seed the Random Number Generator for Reproducibility\n",
        "# You can comment the next line out see the variability\n",
        "torch.manual_seed(99)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2aPOZPhtrIVp",
        "outputId": "1b235e5b-0838-4951-cbb1-c2809415fbd1"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7fb7e81e48f0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "clGIR99BE1DJ",
        "outputId": "9dd780ed-ac42-4c19-b0dc-2c98886115b5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ptMLP(\n",
            "  (layers): Sequential(\n",
            "    (0): Linear(in_features=3, out_features=6, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (5): ReLU()\n",
            "    (6): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (7): ReLU()\n",
            "    (8): Linear(in_features=6, out_features=6, bias=True)\n",
            "    (9): ReLU()\n",
            "    (10): Linear(in_features=6, out_features=1, bias=True)\n",
            "  )\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "# Step 1: Define the MLP model\n",
        "class ptMLP(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(ptMLP, self).__init__()\n",
        "        self.layers = nn.Sequential(\n",
        "            nn.Linear(3, 6),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(6, 6),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(6, 6),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(6, 6),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(6, 6),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(6, 1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.layers(x)\n",
        "\n",
        "model = ptMLP()\n",
        "print(model)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "713gjL-8E1DJ"
      },
      "source": [
        "Define a loss function and an optimizer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "id": "ZLFZZfB3E1DJ"
      },
      "outputs": [],
      "source": [
        "# Step 2: Define a loss function and an optimizer\n",
        "criterion = nn.MSELoss(reduction='sum')\n",
        "optimizer = SGD(model.parameters(), lr=0.01)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "johmojsuE1DJ"
      },
      "source": [
        "Recreate the tiny dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "bIBQQlzbE1DJ"
      },
      "outputs": [],
      "source": [
        "#| code-fold: false\n",
        "# Step 3: Create a tiny dataset\n",
        "xs = [\n",
        "    [2.0, 3.0, -1.0],\n",
        "    [3.0, -1.0, 0.5],\n",
        "    [0.5, 1.0, 1.0],\n",
        "    [1.0, 1.0, -1.0]\n",
        "]\n",
        "\n",
        "# we had to transpose ys for torch.tensor\n",
        "ys_transpose = [[1.0],\n",
        "      [0.0],\n",
        "      [0.0],\n",
        "      [1.0]]\n",
        "\n",
        "inputs = torch.tensor(xs)\n",
        "outputs = torch.tensor(ys_transpose)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inputs.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OBvtI1CwHWZ",
        "outputId": "4aeab7a7-319d-4802-b675-324cfaf179a7"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 3])"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "outputs.size()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeVeUUhtwKGN",
        "outputId": "9c93764c-5bb3-417f-b579-f69ce527ebd4"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([4, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1FHYPMsE1DJ"
      },
      "source": [
        "Define and run the training loop."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yuTg63fvE1DJ",
        "outputId": "24b43aab-690c-4d1e-99ac-86b6c175c943"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Final Loss: 0.004101179540157318\n"
          ]
        }
      ],
      "source": [
        "# Step 4: Write the training loop\n",
        "losses = []\n",
        "niters = 300\n",
        "\n",
        "for epoch in range(niters):\n",
        "\n",
        "    # Training Step 1: Forward pass\n",
        "    predictions = model(inputs)\n",
        "\n",
        "    # Training Step 2: Calculate the loss\n",
        "    loss = criterion(predictions, outputs)\n",
        "\n",
        "    # Training Step 3: Zero the gradient and run backward pass\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "\n",
        "    # Training Step 4: Update parameters\n",
        "    optimizer.step()\n",
        "\n",
        "    losses.append(loss.item())\n",
        "    # print(f'Epoch {epoch+1}, Loss: {loss.item()}')\n",
        "\n",
        "print(f'Final Loss: {loss.item()}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZzdfSgqCE1DJ"
      },
      "source": [
        "Plot the loss over the iterations."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "KQ6ItuP3E1DJ",
        "outputId": "32feba10-598b-4afa-f7d7-d5df8dbd13b1"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQAAUdxJREFUeJzt3XlYVGX/BvD7zMAM+yCyL4KIG4KoqIi7iaKpaWaZ9bpQ2mb9Mm2jUjNLWn2tNC2rV+0tNc2l18wlVMwkF5DcURQElVWEYZFt5vz+QCYnEQGBM8v9ua65kOc8Z+Y7j4PcPuc55wiiKIogIiIiMhEyqQsgIiIiakoMN0RERGRSGG6IiIjIpDDcEBERkUlhuCEiIiKTwnBDREREJoXhhoiIiEwKww0RERGZFIYbIiIiMikMN0REBuTtt9+GIAhSl0Fk1BhuiIzQqlWrIAgCjh49KnUpdar5RV3zsLGxQWBgIN566y2o1epmf/1p06bBzs5Or+2LL77AqlWrmv2161JaWoq3334b+/btk7QOIlPFcENEzW758uX47rvvsHjxYnTq1AnvvfceRowYASlubWco4WbBggW1hpu33noLN27caPmiiEyIhdQFEJHpmzBhApydnQEAzzzzDB566CFs2rQJf/75J8LDwxv9vKIooqysDNbW1k1VaqNUVVVBq9VCoVDc83NZWFjAwoL/NBPdC87cEJmwY8eOYeTIkXBwcICdnR2GDh2KP//8U69PZWUlFixYgPbt28PKygqtW7dG//79sXv3bl2frKwsREVFwdvbG0qlEh4eHhg7dizS0tIaVdd9990HAEhNTQUAaLVaLFmyBF26dIGVlRXc3Nzw9NNP4/r163r7+fn5YfTo0di5cyd69uwJa2trfPnll/V+XT8/P5w6dQpxcXG6Q2WDBw/WbS8oKMCsWbPg4+MDpVKJgIAAfPDBB9Bqtbo+aWlpEAQBH3/8MZYsWYJ27dpBqVTi9OnTqKiowLx58xAaGgqVSgVbW1sMGDAAe/fu1dvfxcUFALBgwQJdHW+//TaA2tfcVFVVYeHChbrX8vPzwxtvvIHy8vJax+fAgQPo3bs3rKys4O/vjzVr1tR7jIhMAf97QGSiTp06hQEDBsDBwQGvvvoqLC0t8eWXX2Lw4MGIi4tDWFgYgOpfpjExMZg+fTp69+4NtVqNo0ePIjExEcOGDQMAPPTQQzh16hReeOEF+Pn5IScnB7t370Z6ejr8/PwaXNuFCxcAAK1btwYAPP3001i1ahWioqLwf//3f0hNTcXSpUtx7Ngx/PHHH7C0tNTtm5ycjEmTJuHpp5/GjBkz0LFjx3q/7pIlS/DCCy/Azs4Ob775JgDAzc0NQPWhokGDBuHKlSt4+umn0aZNGxw8eBDR0dHIzMzEkiVL9J7rP//5D8rKyvDUU09BqVTCyckJarUaX3/9NSZNmoQZM2agqKgI33zzDSIjI3H48GF069YNLi4uWL58OZ599lk8+OCDGD9+PACga9eud6x7+vTpWL16NSZMmIA5c+bg0KFDiImJwZkzZ7B582a9vikpKZgwYQKefPJJTJ06Fd9++y2mTZuG0NBQdOnSpd5jRWTURCIyOv/5z39EAOKRI0fu2GfcuHGiQqEQL1y4oGu7evWqaG9vLw4cOFDXFhISIo4aNeqOz3P9+nURgPjRRx81uM758+eLAMTk5GQxNzdXTE1NFb/88ktRqVSKbm5uYklJifj777+LAMTvv/9eb98dO3bc1u7r6ysCEHfs2FGv1586dapoa2ur19alSxdx0KBBt/VduHChaGtrK547d06v/fXXXxflcrmYnp4uiqIopqamigBEBwcHMScnR69vVVWVWF5ertd2/fp10c3NTXziiSd0bbm5uSIAcf78+bfVUTNmNZKSkkQA4vTp0/X6vfzyyyIAcc+ePbq2mvHZv3+/ri0nJ0dUKpXinDlzbnstIlPFw1JEJkij0WDXrl0YN24c/P39de0eHh547LHHcODAAd3ZSo6Ojjh16hTOnz9f63NZW1tDoVBg3759tx0mqq+OHTvCxcUFbdu2xdNPP42AgAD88ssvsLGxwYYNG6BSqTBs2DDk5eXpHqGhobCzs9M7pAMAbdu2RWRkZKPqqMuGDRswYMAAtGrVSq+OiIgIaDQa7N+/X6//Qw89pDu8VEMul+vW3Wi1WuTn56Oqqgo9e/ZEYmJio+ravn07AGD27Nl67XPmzAEA/PLLL3rtgYGBGDBggO57FxcXdOzYERcvXmzU6xMZIx6WIjJBubm5KC0trfWQTefOnaHVapGRkYEuXbrgnXfewdixY9GhQwcEBQVhxIgRmDx5su4wiVKpxAcffIA5c+bAzc0Nffr0wejRozFlyhS4u7vXq56ffvoJDg4OsLS0hLe3N9q1a6fbdv78eRQWFsLV1bXWfXNycvS+b9u2bX2HoUHOnz+P48eP3xZYGlrH6tWr8cknn+Ds2bOorKy8a/+7uXTpEmQyGQICAvTa3d3d4ejoiEuXLum1t2nT5rbnaNWqVaODKZExYrghMnMDBw7EhQsXsHXrVuzatQtff/01/v3vf2PFihWYPn06AGDWrFkYM2YMtmzZgp07d2Lu3LmIiYnBnj170L1793q9Rs3ZUv+k1Wrh6uqK77//vtbt/wwbzXVmlFarxbBhw/Dqq6/Wur1Dhw53reO///0vpk2bhnHjxuGVV16Bq6sr5HI5YmJidOuMGqu+F/aTy+W1tosSnHZPJBWGGyIT5OLiAhsbGyQnJ9+27ezZs5DJZPDx8dG1OTk5ISoqClFRUSguLsbAgQPx9ttv68INALRr1w5z5szBnDlzcP78eXTr1g2ffPIJ/vvf/95Tre3atcNvv/2Gfv36tcgp3XcKCe3atUNxcTEiIiIa/dwbN26Ev78/Nm3apPc68+fPr1cNtfH19YVWq8X58+fRuXNnXXt2djYKCgrg6+vb6HqJTBXX3BCZILlcjuHDh2Pr1q16p2tnZ2fjhx9+QP/+/eHg4AAAuHbtmt6+dnZ2CAgI0J1mXFpairKyMr0+7dq1g729/W2nIjfGI488Ao1Gg4ULF962raqqCgUFBff8GreytbWt9TkfeeQRxMfHY+fOnbdtKygoQFVV1V2fu2bW5NZZkkOHDiE+Pl6vn42Nje557+b+++8HgNvO1lq8eDEAYNSoUXd9DiJzw5kbIiP27bffYseOHbe1v/jii3j33Xexe/du9O/fH8899xwsLCzw5Zdfory8HB9++KGub2BgIAYPHozQ0FA4OTnh6NGj2LhxI55//nkAwLlz5zB06FA88sgjCAwMhIWFBTZv3ozs7Gw8+uij9/weBg0ahKeffhoxMTFISkrC8OHDYWlpifPnz2PDhg349NNPMWHChHt+nRqhoaFYvnw53n33XQQEBMDV1RX33XcfXnnlFfz8888YPXq07tTpkpISnDhxAhs3bkRaWtodD63VGD16NDZt2oQHH3wQo0aNQmpqKlasWIHAwEAUFxfr+llbWyMwMBDr169Hhw4d4OTkhKCgIAQFBd32nCEhIZg6dSq++uorFBQUYNCgQTh8+DBWr16NcePGYciQIU02NkQmQ+rTtYio4WpOBb/TIyMjQxRFUUxMTBQjIyNFOzs70cbGRhwyZIh48OBBved69913xd69e4uOjo6itbW12KlTJ/G9994TKyoqRFEUxby8PHHmzJlip06dRFtbW1GlUolhYWHijz/+eNc6a05rzs3NvWvfr776SgwNDRWtra1Fe3t7MTg4WHz11VfFq1ev6vr4+vrWedr6P9V2KnhWVpY4atQo0d7eXgSgd1p4UVGRGB0dLQYEBIgKhUJ0dnYW+/btK3788ce68ag5Fby2U+O1Wq24aNEi0dfXV1QqlWL37t3Fbdu2iVOnThV9fX31+h48eFAMDQ0VFQqF3mnh/zwVXBRFsbKyUlywYIHYtm1b0dLSUvTx8RGjo6PFsrIyvX53Gp9BgwbVevo7kakSRJGrzIiIiMh0cM0NERERmRSGGyIiIjIpDDdERERkUhhuiIiIyKQw3BAREZFJYbghIiIik2J2F/HTarW4evUq7O3tG3QJdCIiIpKOKIooKiqCp6cnZLK652bMLtxcvXpV7546REREZDwyMjLg7e1dZx+zCzf29vYAqgen5t46REREZNjUajV8fHx0v8frYnbhpuZQlIODA8MNERGRkanPkhIuKCYiIiKTImm42b9/P8aMGQNPT08IgoAtW7bU2X/Tpk0YNmwYXFxc4ODggPDwcOzcubNliiUiIiKjIGm4KSkpQUhICJYtW1av/vv378ewYcOwfft2JCQkYMiQIRgzZgyOHTvWzJUSERGRsTCYu4ILgoDNmzdj3LhxDdqvS5cumDhxIubNm1ev/mq1GiqVCoWFhVxzQ0REZCQa8vvbqBcUa7VaFBUVwcnJ6Y59ysvLUV5ervterVa3RGlEREQkEaNeUPzxxx+juLgYjzzyyB37xMTEQKVS6R68xg0REZFpM9pw88MPP2DBggX48ccf4erqesd+0dHRKCws1D0yMjJasEoiIiJqaUZ5WGrdunWYPn06NmzYgIiIiDr7KpVKKJXKFqqMiIiIpGZ0Mzdr165FVFQU1q5di1GjRkldDhERERkYSWduiouLkZKSovs+NTUVSUlJcHJyQps2bRAdHY0rV65gzZo1AKoPRU2dOhWffvopwsLCkJWVBQCwtraGSqWS5D0QERGRYZF05ubo0aPo3r07unfvDgCYPXs2unfvrjutOzMzE+np6br+X331FaqqqjBz5kx4eHjoHi+++KIk9RMREZHhMZjr3LQUXueGiIjI+DTk97fRrbkxVFqtiJyiMqTmlUhdChERkVljuGkiv6fkofd7sXjmuwSpSyEiIjJrDDdNxFNlBQC4WnhD4kqIiIjMG8NNE/FwtAYAFJVVobi8SuJqiIiIzBfDTROxU1rA3qr6zPoszt4QERFJhuGmCXnUHJoqKJO4EiIiIvPFcNOEPFTVh6YyOXNDREQkGYabJuTpWD1zk1nImRsiIiKpMNw0Id3MDQ9LERERSYbhpgm583RwIiIiyTHcNCFP3ZobztwQERFJheGmCXncXHOTxXBDREQkGYabJlRzKnhxeRXUZZUSV0NERGSeGG6akI3CAiprSwBcVExERCQVhpsm5sFFxURERJJiuGliXjfvMXX5OsMNERGRFBhumlhbZ1sAQFpeicSVEBERmSeGmybW1qU63KQy3BAREUmC4aaJ1czcMNwQERFJg+Gmifk72wEA0vNLUanRSlwNERGR+WG4aWJuDkpYW8qh0YrIyC+VuhwiIiKzw3DTxARB0B2aupjLQ1NEREQtjeGmGXBRMRERkXQYbpqBf83MDcMNERFRi2O4aQZ/nzFVLHElRERE5ofhphn4u1SfMZWSw5kbIiKilsZw0ww6utlDJgB5xeXIUfMGmkRERC2J4aYZWCvkCHCtnr05caVQ4mqIiIjMC8NNMwnyVAEATl5RS1wJERGReWG4aSZdvG6Gm6ucuSEiImpJDDfNJPhmuDnFw1JEREQtiuGmmQR6OgAArhaW4VpxucTVEBERmQ+Gm2Zip7TQXczv5FWuuyEiImopDDfNqKt39aGphEvXJa6EiIjIfDDcNKM+/q0BAPEX8iSuhIiIyHww3DSjvu2cAQDH0gtQWlElcTVERETmgeGmGfk4WcPL0RpVWhFH0nhoioiIqCUw3DQjQRDQt131oamDPDRFRETUIhhumlnfgOpw80cKww0REVFLYLhpZv0CnCEI1bdhyMgvlbocIiIik8dw08xc7a3Qp2317M2245kSV0NERGT6GG5awAPdPAEAP/91VeJKiIiITB/DTQsYGeQOC5mAM5lqpOQUSV0OERGRSWO4aQGONgoM6uACAFh7OEPiaoiIiEwbw00LmRzuCwBYfyQDRWWVEldDRERkuhhuWsigDi4IcLVDcXkV1h/h7A0REVFzYbhpIYIg4Il+bQEA3xxIxY0KjcQVERERmSZJw83+/fsxZswYeHp6QhAEbNmy5a777Nu3Dz169IBSqURAQABWrVrV7HU2lfE9vODlaI3MwjIsj7sgdTlEREQmSdJwU1JSgpCQECxbtqxe/VNTUzFq1CgMGTIESUlJmDVrFqZPn46dO3c2c6VNw8pSjjdHdQYArIi7gPRrvKgfERFRUxNEURSlLgKoPmyzefNmjBs37o59XnvtNfzyyy84efKkru3RRx9FQUEBduzYUa/XUavVUKlUKCwshIODw72W3WCiKOJf3xzCHynX0NO3FdY91QcWch4dJCIiqktDfn8b1W/V+Ph4RERE6LVFRkYiPj7+jvuUl5dDrVbrPaQkCALeH98VdkoLHL10HUv3pkhaDxERkakxqnCTlZUFNzc3vTY3Nzeo1WrcuHGj1n1iYmKgUql0Dx8fn5YotU4+TjZYOK4LAGDJb+fx3z8vSVwRERGR6TCqcNMY0dHRKCws1D0yMgzjNOxx3bzw1EB/AMBbW05i5f6LMJAjhEREREbNQuoCGsLd3R3Z2dl6bdnZ2XBwcIC1tXWt+yiVSiiVypYor0EEQUD0yE4QRRErf0/Fe9vPID2/FG+O6gwrS7nU5RERERkto5q5CQ8PR2xsrF7b7t27ER4eLlFF90YQBLxxf2e8cX8nAMB3f17CuGV/4EhavsSVERERGS9Jw01xcTGSkpKQlJQEoPpU76SkJKSnpwOoPqQ0ZcoUXf9nnnkGFy9exKuvvoqzZ8/iiy++wI8//oiXXnpJivKbhCAIeGpgO3w7rSec7RQ4m1WEh1fEY/rqoziXzZtsEhERNZSkp4Lv27cPQ4YMua196tSpWLVqFaZNm4a0tDTs27dPb5+XXnoJp0+fhre3N+bOnYtp06bV+zWlPhW8LnnF5Vi8+xzWH8mARitCEICIzm6YGu6HfgGtIQiC1CUSERFJoiG/vw3mOjctxZDDTY2UnGJ8tPMsdp76e32Rv4stRgV74L5OrgjxdoRMxqBDRETmg+GmDsYQbmqk5BThu/hL2JhwGSW33IvK2U6BIR1dMbSzK/q3d4Gd0qjWhRMRETUYw00djCnc1Cgur8LOk1nYczYH+8/loqi8SrdNIZchzN8JQzu5YmhnN/g42UhYKRERUfNguKmDMYabW1VUaXE0LR+xZ3MQeyYbaf+4P1UHNzsM6eiKfgHO6OXnBGsFTysnIiLjx3BTB2MPN7cSRREX80qw50wOfjuTjaOXrkOj/fuvUyGXIdS3Ffq3d0a/AGcEe6kg51odIiIyQgw3dTClcPNPhaWViDufi9/P5eKPlDxcLSzT2+5gZYHwdq3RL6A67Pg72/IMLCIiMgoMN3Uw5XBzK1EUkZpXgj9S8nAgJQ/xF65BXVal18fdwQp927VG3wBnDGzvDFcHK4mqJSIiqhvDTR3MJdz8k0Yr4uSVQhxIycOB83lISL+OiiqtXp/OHg4Y1MEFAzs4o6evExQWRnUBayIiMmEMN3Uw13DzT2WVGiRcuq6b2Tl+uVBvu61CjvB2rW+GHRf4traVqFIiIiKGmzox3NQur7gcB87nYf+5XOw/n4u84gq97X6tbTCwgwsGdXBBH//WsOW1dYiIqAUx3NSB4ebutFoRpzPViDuXi/3ncpFw6Tqqbj0Ly0KGge2dMSLIAxGdXeFoo5CwWiIiMgcMN3VguGm4orJKxF+4hrhzuYg7l4vL12/otsllAsL9WyMyyB2RgW5clExERM2C4aYODDf3RhRFJGcXYcfJLOw4mYWzWX/fuVwQgNA2rTAiyB2RXdx5tWQiImoyDDd1YLhpWql5Jdh5qjroJGUU6G3r5dcKkV3cMbSzG9o6c0EyERE1HsNNHRhumk9m4Q3sOpWNX09m4lBqPm79ZPVo44hx3b0wPNAd7ioeuiIiooZhuKkDw03LyCoswy8nMrEvOQcHL1zTuy1EiI8jRgW7Y1RXT3g5WktYJRERGQuGmzow3LS8HHUZtiRdwc5T2UhMv643o9PTl2t0iIjo7hhu6sBwI60cdRl2nc7G//66isNp+oeu+rZrjX/18cWwQDdYynl1ZCIi+hvDTR0YbgxHVmEZtp/IxK7TWXprdFrbKtC/vTMiu7gjorMbbwNBREQMN3VhuDFMl6+XYt3hDKw7koG84nJdu5OtAuO7e2FiLx+0d7OXsEIiIpISw00dGG4MW6VGi4RL17E3OQebE68gp+jvoNO9jSMe7eWD0V09efsHIiIzw3BTB4Yb41Gl0SLuXC7WH8nAnrM5ultA2FtZ4LHebTC1rx88ebYVEZFZYLipA8ONccopKsOmxCtYfyQDqXklAKpv/TC0kyseCvVGRGc3yGWCxFUSEVFzYbipA8ONcdNqRexNzsE3B1Jx8MI1XXt7Vzs8O7gd7g/2gJWlXMIKiYioOTDc1IHhxnQkZxVhU+JlrD2cDnVZFQBAZW2JB7t7YUq4L/xd7CSukIiImgrDTR0YbkxP4Y1KrDmYhnVHMnCloPqO5XKZgIdDvfHMoHbw432tiIiMHsNNHRhuTJdGK+L387lYE38Je87mAKi+U/mwzm6YPsAfvfxaQRC4LoeIyBgx3NSB4cY8HE3Lx9K9KdiXnKtrC/ZS4dnB7TAyyJ0hh4jIyDDc1IHhxryk5BThmwNp2JR4GeVVWgBAqG8rvDmqM3q0aSVxdUREVF8MN3VguDFP14rLsfpgGlb+nooblRoAwOiuHnhtRCfesJOIyAgw3NSB4ca8ZavL8PHOZGxMvAxRBBRyGaL6+eG5IQFQWVtKXR4REd0Bw00dGG4IAE5dLcSi7WfwR0r1tXJa2VhiVkQHPB7WBha8IzkRkcFhuKkDww3VEMXqCwIu2n4WKTnFAIAung6IGR+Mrt6O0hZHRER6GG7qwHBD/1Sl0WLtkQx8vDMZhTcqIROAqH5tMXtYB96gk4jIQDTk9zfn38nsWchlmNzHF7FzBmFsN09oReCbA6kY/u/92HvzejlERGQ8GG6IbnK2U+LTR7tjVVQveLeyxpWCG4hadQTP/5CInKIyqcsjIqJ6Yrgh+ofBHV2x66WBeGqgP2QCsO14JiI+icP6I+kws6O4RERGieGGqBY2Cgu8cX9n/Px8fwR7qaAuq8JrP53AjDVHkVdcLnV5RERUB4YbojoEeamw+bm+iB7ZCQq5DL+dycGIJfsReyZb6tKIiOgOGG6I7sJCLsPTg9ph6/P90NHNHnnFFXhy9VFEbzqB0ooqqcsjIqJ/YLghqqfOHg7Y+nw/TO/fFgCw9nA6Hloej4z8UokrIyKiWzHcEDWAlaUcb40OxPfTw+Bsp8CZTDXu/+x3fHMgFVUardTlERERGG6IGqVfgDN+fr4/QnwcUVRWhYXbTuPp7xJQdvOmnEREJB2GG6JG8nS0xqZn+2LRg8FQWsgQezYHU749zGviEBFJjOGG6B7IZQIeC2uD1U/0hp3SAodT8zFyye/4IyVP6tKIiMwWww1RE+jj3xpbZvZDJ3d7XCupwORvDuHr3y/yon9ERBJguCFqIgGudtgysx8e6uENrQi8+8sZzP7xL67DISJqYZKHm2XLlsHPzw9WVlYICwvD4cOH6+y/ZMkSdOzYEdbW1vDx8cFLL72EsjKucSDDYGUpx8cPd8X8MYGQywRsPnYFE1YcxJWCG1KXRkRkNiQNN+vXr8fs2bMxf/58JCYmIiQkBJGRkcjJqf1OzD/88ANef/11zJ8/H2fOnME333yD9evX44033mjhyonuTBAERPVri++e7I1WNpY4eUWNsUv/QGpeidSlERGZBUnDzeLFizFjxgxERUUhMDAQK1asgI2NDb799tta+x88eBD9+vXDY489Bj8/PwwfPhyTJk2662wPkRT6tqs+Xbz6qsblmPzNIWQVcpaRiKi5SRZuKioqkJCQgIiIiL+LkckQERGB+Pj4Wvfp27cvEhISdGHm4sWL2L59O+6///47vk55eTnUarXeg6il+DjZ4L/Tw+DX2gaXr9/AmKUHcOjiNanLIiIyaZKFm7y8PGg0Gri5uem1u7m5ISsrq9Z9HnvsMbzzzjvo378/LC0t0a5dOwwePLjOw1IxMTFQqVS6h4+PT5O+D6K7cbFX4rsnw9DRzR65ReV4/OtD2Hb8qtRlERGZLMkXFDfEvn37sGjRInzxxRdITEzEpk2b8Msvv2DhwoV33Cc6OhqFhYW6R0ZGRgtWTFTNx8kGm2f2xahgD1RpRfzf2mPYmHBZ6rKIiEyShVQv7OzsDLlcjuzsbL327OxsuLu717rP3LlzMXnyZEyfPh0AEBwcjJKSEjz11FN48803IZPdntWUSiWUSmXTvwGiBrJRWOCzSd3hYG2JtYfT8erGv2CjkOP+YA+pSyMiMimSzdwoFAqEhoYiNjZW16bVahEbG4vw8PBa9yktLb0twMjlcgDgxdLIKMhlAhY9GISJPX2gFYH/W3sMW5OuSF0WEZFJkWzmBgBmz56NqVOnomfPnujduzeWLFmCkpISREVFAQCmTJkCLy8vxMTEAADGjBmDxYsXo3v37ggLC0NKSgrmzp2LMWPG6EIOkaETBAGLxgejvEqDLUlXMWt9EsortXikF9eDERE1BUnDzcSJE5Gbm4t58+YhKysL3bp1w44dO3SLjNPT0/Vmat566y0IgoC33noLV65cgYuLC8aMGYP33ntPqrdA1ChymYDFj3SDg7Ul1sRfQvTmE3C2V+C+Tm5335mIiOokiGZ2PEetVkOlUqGwsBAODg5Sl0NmThRFvLLxODYmXIa1pRxrn+qDbj6OUpdFRGRwGvL726jOliIyNYIgIGZ8MAZ1cMGNSg2eWHWEVzImIrpHDDdEErOUy/DF4z0Q7KVCfkkFHl/5JzLyS6Uui4jIaDHcEBkAW6UFvp3WC+1cbHG1sAyPfvUnctS8VQMRUWMw3BAZCBd7JdbO6IO2zra4UnAD09ccxY0KjdRlEREZHYYbIgPi6mCFVVG90MrGEscvF+Kl9UnQas1qzT8R0T1juCEyML6tbfHVlJ5QyGXYcSoLH+w8K3VJRERGheGGyAD18nPChxO6AgC+jLuItYfTJa6IiMh4MNwQGahx3b3w4tD2AIC5W07i9/O5EldERGQcGG6IDNisiPYY280TVVoRT3+XgMT061KXRERk8BhuiAyYIAj4cEJXDGjvjNIKDaZ9exgXcoulLouIyKAx3BAZOKWFHF9ODkX3No5Ql1XhqTVHUVRWKXVZREQGi+GGyAjYKCzw5eRQuDtY4UJuCV5a/xdPESciugOGGyIj4WpvhS8nh0JhIcNvZ7KxJPa81CURERkkhhsiIxLi44iYB4MBAJ/FnseOk1kSV0REZHgYboiMzEOh3ojq5wcAmPNjEs5lF0lbEBGRgWG4ITJCb9zfGeH+rVFSocFTa46isJQLjImIajDcEBkhS7kMyx7vAS9Ha6RdK8UL645BwwXGREQAGG6IjJaTrQJfTQmFlaUM+8/l4qOdyVKXRERkEBhuiIxYF08VPpoQAgBYEXcB//vrqsQVERFJj+GGyMiNCfHEM4PaAQBe/+k40vJKJK6IiEhaDDdEJuCVyI7o3dYJJRUavLD2GMqrNFKXREQkGYYbIhMglwn49NFucLSxxIkrhXhr80mIIhcYE5F5YrghMhEeKmt89mh3yARgQ8Jl/OePNKlLIiKSBMMNkQkZ2MEFb9zfGQDw7i+nsf9crsQVERG1PIYbIhPzZP+2mBDqDa0IPP9DIo6lX5e6JCKiFsVwQ2RiBEHAew8GoadvK6jLqjBp5Z/Ym5wjdVlERC2G4YbIBCkt5Fj9RG8M6eiCskot/u+HY8jIL5W6LCKiFsFwQ2SibJUW+GpKT4T6tkJReRVmrU9ClUYrdVlERM2O4YbIhFnKZVgysRvslRZIuHQdn+9JkbokIqJmx3BDZOJ8nGzw7oNBAIDP95zHkbR8iSsiImpeDDdEZmBsNy+M7+EFrQj839pjyC+pkLokIqJmw3BDZCbeGRsEf2dbZBaWYdb6JGi1vIIxEZkmhhsiM2GntMAX/+oBK0sZ9p/LxbK9XH9DRKaJ4YbIjHRyd8DCsdXrb/792zn8kZIncUVERE2P4YbIzDzc0weP9Ky+gvGL644hW10mdUlERE2K4YbIDL0zNgid3O2RV1yBF344xuvfEJFJYbghMkNWlnIs/1co7JQWOJyWj492JUtdEhFRk2G4ITJTbZ1t8eGErgCAL+MuYvfpbIkrIiJqGgw3RGbs/mAPRPXzAwC8svEvZBVy/Q0RGT+GGyIzFz2yM4K9VCgorcTsH3n9GyIyfgw3RGZOYSHDp492g7WlHAcvXMNXv1+UuiQionvCcENE8Hexw9sPBAIAPt6ZjOOXC6QtiIjoHjDcEBEA4JGePhgZ5I4qrYhZ65Jwo0IjdUlERI3SqHCTkZGBy5cv674/fPgwZs2aha+++qrJCiOiliUIAmLGB8PNQYmLeSWI+fWM1CURETVKo8LNY489hr179wIAsrKyMGzYMBw+fBhvvvkm3nnnnSYtkIhajqONAh9NCAEArIm/hP3nciWuiIio4RoVbk6ePInevXsDAH788UcEBQXh4MGD+P7777Fq1aqmrI+IWtjADi6YEu4LoPr08ILSCokrIiJqmEaFm8rKSiiVSgDAb7/9hgceeAAA0KlTJ2RmZjZddUQkieiRneHvbItsdTnmbj0ldTlERA3SqHDTpUsXrFixAr///jt2796NESNGAACuXr2K1q1bN+i5li1bBj8/P1hZWSEsLAyHDx+us39BQQFmzpwJDw8PKJVKdOjQAdu3b2/M2yCiO7BWyPHvid0glwn4319X8fNfV6UuiYio3hoVbj744AN8+eWXGDx4MCZNmoSQkOpj9D///LPucFV9rF+/HrNnz8b8+fORmJiIkJAQREZGIicnp9b+FRUVGDZsGNLS0rBx40YkJydj5cqV8PLyaszbIKI6hPg44vkhAQCAtzaf4NWLichoCKIoNupypBqNBmq1Gq1atdK1paWlwcbGBq6urvV6jrCwMPTq1QtLly4FAGi1Wvj4+OCFF17A66+/flv/FStW4KOPPsLZs2dhaWnZmLKhVquhUqlQWFgIBweHRj0Hkbmo1Gjx0PKDOH65EAPaO2N1VG/IZILUZRGRGWrI7+9GzdzcuHED5eXlumBz6dIlLFmyBMnJyfUONhUVFUhISEBERMTfxchkiIiIQHx8fK37/PzzzwgPD8fMmTPh5uaGoKAgLFq0CBrNna/HUV5eDrVarfcgovqxlMuw+JFuUFrI8Pv5PHz35yWpSyIiuqtGhZuxY8dizZo1AKrXwISFheGTTz7BuHHjsHz58no9R15eHjQaDdzc3PTa3dzckJWVVes+Fy9exMaNG6HRaLB9+3bMnTsXn3zyCd599907vk5MTAxUKpXu4ePjU893SUQAEOBqh+iRnQAAMb+ewYXcYokrIiKqW6PCTWJiIgYMGAAA2LhxI9zc3HDp0iWsWbMGn332WZMWeCutVgtXV1d89dVXCA0NxcSJE/Hmm29ixYoVd9wnOjoahYWFukdGRkaz1UdkqqaE+6F/gDPKKrWYvT4JlRqt1CUREd1Ro8JNaWkp7O3tAQC7du3C+PHjIZPJ0KdPH1y6VL9pa2dnZ8jlcmRnZ+u1Z2dnw93dvdZ9PDw80KFDB8jlcl1b586dkZWVhYqK2q/FoVQq4eDgoPcgooaRyQR89HBXOFhZ4K/LhVi2N0XqkoiI7qhR4SYgIABbtmxBRkYGdu7cieHDhwMAcnJy6h0eFAoFQkNDERsbq2vTarWIjY1FeHh4rfv069cPKSkp0Gr//l/juXPn4OHhAYVC0Zi3QkT15KGyxsJxQQCAz/ek4K+MAmkLIiK6g0aFm3nz5uHll1+Gn58fevfurQsju3btQvfu3ev9PLNnz8bKlSuxevVqnDlzBs8++yxKSkoQFRUFAJgyZQqio6N1/Z999lnk5+fjxRdfxLlz5/DLL79g0aJFmDlzZmPeBhE10NhuXhjd1QMarYiXfuTNNYnIMFk0ZqcJEyagf//+yMzM1F3jBgCGDh2KBx98sN7PM3HiROTm5mLevHnIyspCt27dsGPHDt0i4/T0dMhkf+cvHx8f7Ny5Ey+99BK6du0KLy8vvPjii3jttdca8zaIqBHeHReEI2n5uJhbgg92nMXbD3SRuiQiIj2Nvs5NjZq7g3t7ezdJQc2N17khundx53Ix9dvqq4l/Pz0M/QKcJa6IiExds1/nRqvV4p133oFKpYKvry98fX3h6OiIhQsX6q2HISLTNKiDC/7Vpw0AIHrTCR6eIiKD0qhw8+abb2Lp0qV4//33cezYMRw7dgyLFi3C559/jrlz5zZ1jURkgF4b0QkeKiuk55diyW/npC6HiEinUYelPD09sWLFCt3dwGts3boVzz33HK5cudJkBTY1HpYiajqxZ7Lx5OqjkAnAz8/3R5CXSuqSiMhENfthqfz8fHTq1Om29k6dOiE/P78xT0lERmhoZzeM7uoBrQi8uvE4L+5HRAahUeEmJCREd7PLWy1duhRdu3a956KIyHjMH9MFKmtLnM5U45sDqVKXQ0TUuFPBP/zwQ4waNQq//fab7ho38fHxyMjIwPbt25u0QCIybC72Srw1qjNe2Xgc/959DiO6uMPP2VbqsojIjDVq5mbQoEE4d+4cHnzwQRQUFKCgoADjx4/HqVOn8N133zV1jURk4CaEeqNfQGuUV2nxxuYTuMcrTBAR3ZN7vs7Nrf766y/06NEDGo3hnhbKBcVEzSP9WimGL4lDWaUWSyZ2w7juXlKXREQmpNkXFBMR/VOb1jZ44b72AIB3fzmNwtJKiSsiInPFcENETWbGAH8EuNohr7gCH+06K3U5RGSmGG6IqMkoLGRYOLb6zuHfH0pHEu8cTkQSaNDZUuPHj69ze0FBwb3UQkQmILxda4zv4YVNiVfw5uYT2DqzHyzk/H8UEbWcBoUblaruq4+qVCpMmTLlngoiIuP3xv2dEXsmB6euqrEm/hKe6N9W6pKIyIw06dlSxoBnSxG1jO8PXcKbm0/CTmmB2DmD4OZgJXVJRGTEeLYUEUluUq826N7GEcXlVXhn22mpyyEiM8JwQ0TNQiYT8O64IMgE4JfjmYg7lyt1SURkJhhuiKjZdPFUIapf9XqbeVtPoqzScC/wSUSmg+GGiJrVS8M6wN3BCpeuleKLvSlSl0NEZoDhhoialZ3SAvPGBAIAVsRdxIXcYokrIiJTx3BDRM1uZJA7Bnd0QYVGi7lbTvLGmkTUrBhuiKjZCYKAdx4IgtJChoMXruHnv65KXRIRmTCGGyJqEdU31gwAACzcdgZFZbyxJhE1D4YbImoxMwb6w9/ZFnnF5fgs9rzU5RCRiWK4IaIWo7SQY+7NxcX/+SMNKTlcXExETY/hhoha1JCOrojo7IoqrYgF/zvFxcVE1OQYboioxc0dHQiFXIbfz+dh9+lsqcshIhPDcENELc63tS1mDKy+cvHCX07zysVE1KQYbohIEjOHBMDdwQoZ+Tfwnz/SpC6HiEwIww0RScJGYYHXRnYEACzbm4KcojKJKyIiU8FwQ0SSGRvihRAfRxSXV+GTneekLoeITATDDRFJRiYTMG909anhPyZk4OSVQokrIiJTwHBDRJIK9W2FB0I8IYrAwm2neWo4Ed0zhhsiktxrIztBaSHDodR87EvOlbocIjJyDDdEJDkvR2tM6+sHAPhgx1lotZy9IaLGY7ghIoPw7OB2sLeywNmsIvzvOO8aTkSNx3BDRAbB0UaBZwa1AwB8suscKqq0EldERMaK4YaIDEZUPz842ymRnl+K9UfSpS6HiIwUww0RGQwbhQVeHBoAAPg0NgWlFVUSV0RExojhhogMysRebdDGyQZ5xeW8LQMRNQrDDREZFIWFDHOGdwAArNh3AddLKiSuiIiMDcMNERmcMV090dnDAUXlVVged0HqcojIyDDcEJHBkckEvDqi+qaaqw6mIbPwhsQVEZExYbghIoM0uIMLerd1QkWVFp/+dl7qcojIiDDcEJFBEgQBr92cvfnxaAZScoolroiIjAXDDREZrFBfJ0R0doNWBBbvTpa6HCIyEgw3RGTQXonsCEEAtp/Iwl8ZBVKXQ0RGgOGGiAxaR3d7PNjdCwDw8S7O3hDR3RlEuFm2bBn8/PxgZWWFsLAwHD58uF77rVu3DoIgYNy4cc1bIBFJ6qWIDrCUC/j9fB7+vHhN6nKIyMBJHm7Wr1+P2bNnY/78+UhMTERISAgiIyORk5NT535paWl4+eWXMWDAgBaqlIik4uNkg4m9fAAAH+9MhiiKEldERIZM8nCzePFizJgxA1FRUQgMDMSKFStgY2ODb7/99o77aDQaPP7441iwYAH8/f1bsFoiksoL97WH0kKGo5euY9+5XKnLISIDJmm4qaioQEJCAiIiInRtMpkMERERiI+Pv+N+77zzDlxdXfHkk0/e9TXKy8uhVqv1HkRkfNwcrDAl3BcA8Mkuzt4Q0Z1JGm7y8vKg0Wjg5uam1+7m5oasrKxa9zlw4AC++eYbrFy5sl6vERMTA5VKpXv4+Pjcc91EJI1nBrWDrUKOk1fU2Hmq9n8jiIgkPyzVEEVFRZg8eTJWrlwJZ2fneu0THR2NwsJC3SMjI6OZqySi5tLaTokn+rcFACzbe4GzN0RUKwspX9zZ2RlyuRzZ2dl67dnZ2XB3d7+t/4ULF5CWloYxY8bo2rRaLQDAwsICycnJaNeund4+SqUSSqWyGaonIilM6+uHlb9fxIkrhYi/cA19A+r3Hx0iMh+SztwoFAqEhoYiNjZW16bVahEbG4vw8PDb+nfq1AknTpxAUlKS7vHAAw9gyJAhSEpK4iEnIjPQ2k6JR3pW/6zzjuFEVBtJZ24AYPbs2Zg6dSp69uyJ3r17Y8mSJSgpKUFUVBQAYMqUKfDy8kJMTAysrKwQFBSkt7+joyMA3NZORKZrxgB//PfPS/j9fB5OXilEkJdK6pKIyIBIHm4mTpyI3NxczJs3D1lZWejWrRt27NihW2Scnp4OmcyolgYRUTPzcbLBqK6e+N9fV/HV/ov4bFJ3qUsiIgMiiGa2Ik+tVkOlUqGwsBAODg5Sl0NEjXTySiFGf34AMgGIe2UIfJxspC6JiJpRQ35/c0qEiIxSkJcKA9o7QysC3xxIlbocIjIgDDdEZLSmD6i+QvnGhMsoLq+SuBoiMhQMN0RktAYEOMPfxRbF5VX4KeGy1OUQkYFguCEioyWTCZjW1w8AsPpgGrRas1pCSER3wHBDREZtfA9v2CstcDGvBPvP84aaRMRwQ0RGzk5pgQk9vQFUz94QETHcEJHRmxruB0EA9ibnIjWvROpyiEhiDDdEZPT8nG0xpKMrAGBNfJq0xRCR5BhuiMgkTAn3BVB9WnhpBU8LJzJnDDdEZBIGtndBGycbFJVV4eekq1KXQ0QSYrghIpMgkwn4V582AIA18ZdgZneWIaJbMNwQkcl4ONQHCgsZTmeqcSyjQOpyiEgiDDdEZDJa2SowpqsnAOC/8ZckroaIpMJwQ0QmZfLNhcXbjmciv6RC4mqISAoMN0RkUkK8VQj2UqFCo8WPRzOkLoeIJMBwQ0QmRRAETO5TPXvz/aFLvN8UkRliuCEikzMmxBMOVhbIyL+BON5visjsMNwQkcmxVsjxcE8fAFxYTGSOGG6IyCQ9HlZ9zZs9yTnIyC+VuBoiakkMN0Rkkvxd7DCgvTNEEfjhcLrU5RBRC2K4ISKT9a+bC4vXH8lAeZVG4mqIqKUw3BCRyRrayRUeKivkl1Rg+4lMqcshohbCcENEJstCLsOk3tVrb9Yd5jVviMwFww0RmbQJod4QBOBQaj7Sr3FhMZE5YLghIpPm6WiN/gHOAICNCZy9ITIHDDdEZPJqrnnzU+IVXrGYyAww3BCRyRse6AZ7KwtcKbiB+IvXpC6HiJoZww0RmTwrSzkeCPEEAGzgzTSJTB7DDRGZhZpDU7+ezIK6rFLiaoioOTHcEJFZCPFWob2rHcqrtPjlOK95Q2TKGG6IyCwIgoCHe3oD4KEpIlPHcENEZmNcdy/IZQIS0wuQklMsdTlE1EwYbojIbLjaW2FwBxcAwE+JlyWuhoiaC8MNEZmVmkNTmxIvo0qjlbgaImoODDdEZFbu6+QGJ1sFstXl2H8+V+pyiKgZMNwQkVlRWMgwvrsXAGD9ES4sJjJFDDdEZHYm9qq+5k3smRzkFJVJXA0RNTWGGyIyO+3d7NGjjSOqtCI2JV6RuhwiamIMN0Rklh7t1QZA9aEpUeTNNIlMCcMNEZmlUV09YKuQIzWvBIdT86Uuh4iaEMMNEZklW6UFxty8mSYXFhOZFoYbIjJbNQuLfzmRicIbvJkmkalguCEis9XNxxEd3exRXqXF1iQuLCYyFQw3RGS2BEHQzd6sPcyFxUSmguGGiMza+B5eUFjIcCZTjeOXC6Uuh4iaAMMNEZk1RxsF7g9yBwCsPZwucTVE1BQMItwsW7YMfn5+sLKyQlhYGA4fPnzHvitXrsSAAQPQqlUrtGrVChEREXX2JyK6m0d7V1/z5ue/rqK4vEriaojoXkkebtavX4/Zs2dj/vz5SExMREhICCIjI5GTk1Nr/3379mHSpEnYu3cv4uPj4ePjg+HDh+PKFS4GJKLGCWvrBH9nW5RWaPC/v65KXQ4R3SNBlHgFXVhYGHr16oWlS5cCALRaLXx8fPDCCy/g9ddfv+v+Go0GrVq1wtKlSzFlypS79ler1VCpVCgsLISDg8M9109EpuHLuAuI+fUsQrxV2Pp8f6nLIaJ/aMjvb0lnbioqKpCQkICIiAhdm0wmQ0REBOLj4+v1HKWlpaisrISTk1Ot28vLy6FWq/UeRET/9FCoNyzlAv66XIiTV7iwmMiYSRpu8vLyoNFo4Obmptfu5uaGrKysej3Ha6+9Bk9PT72AdKuYmBioVCrdw8fH557rJiLT42ynRGSX6oXF3x/iwmIiYyb5mpt78f7772PdunXYvHkzrKysau0THR2NwsJC3SMjg5dZJ6La/auPLwBga9IVFJXxisVExkrScOPs7Ay5XI7s7Gy99uzsbLi7u9e578cff4z3338fu3btQteuXe/YT6lUwsHBQe9BRFSbsLZOaO9qh9IKDTYf40kKRMZK0nCjUCgQGhqK2NhYXZtWq0VsbCzCw8PvuN+HH36IhQsXYseOHejZs2dLlEpEZkAQBDweVn1a+H//vMQrFhMZKckPS82ePRsrV67E6tWrcebMGTz77LMoKSlBVFQUAGDKlCmIjo7W9f/ggw8wd+5cfPvtt/Dz80NWVhaysrJQXFws1VsgIhMyPtQb1pZynMsuxpG061KXQ0SNIHm4mThxIj7++GPMmzcP3bp1Q1JSEnbs2KFbZJyeno7MzExd/+XLl6OiogITJkyAh4eH7vHxxx9L9RaIyIQ4WFlibDdPANWzN0RkfCS/zk1L43VuiOhuTlwuxJilB2ApF/DH6/fB1b72ExaIqOUYzXVuiIgMUbC3Ct3bOKJSI+K7eM7eEBkbhhsiolo8NcAfAPDdn5dQWsH7TREZE4YbIqJaDO/iDt/WNigorcT6I7w+FpExYbghIqqFXCZg+s3ZmxVxF1BWqZG4IiKqL4YbIqI7eKSnNzxVVshWl3PtDZERYbghIroDpYUcsyI6AAC+2JfCWzIQGQmGGyKiOozv4QV/Z1tcL63EtwfSpC6HiOqB4YaIqA4WchleGlY9e/P17xdxvaRC4oqI6G4YboiI7mJUsAc6ezigqLwKK/ZfkLocIroLhhsioruQyQS8Elk9e7P6YBpy1GUSV0REdWG4ISKqhyEdXdGjjSPKKrVYujdF6nKIqA4MN0RE9SAIAl6J7AQAWHs4HZeulUhcERHdCcMNEVE9hbdrjYEdXFCpEfHeL2ekLoeI7oDhhoioAeaO6gy5TMCu09k4cD5P6nKIqBYMN0REDdDezR6T+/gCAOZtPcnbMhAZIIYbIqIGemlYB7jYK3ExrwRf7OOp4USGhuGGiKiBVNaWWPBAFwDA8n0pOJ9dJHFFRHQrhhsiokYYGeSOiM6uqNSIiN50AlqtKHVJRHQTww0RUSMIgoB3xgbBViHH0UvXsfZIutQlEdFNDDdERI3k6WiNlyM7AgDe334W2bxyMZFBYLghIroHU8L9EOKtQlF5FRb875TU5RARGG6IiO6JXCYgZnxXyGUCtp/IwuZjl6UuicjsMdwQEd2jQE8HvHBfAADgjU0ncY5nTxFJiuGGiKgJvHBfewxo74wblRr839pjqKjSSl0SkdliuCEiagJymYB/T+yG1rYKnM0qwud7zktdEpHZYrghImoiznZKvDsuCADwxb4LiL9wTeKKiMwTww0RURMaGeyBB7t7QaMV8fR3R5GSUyx1SURmh+GGiKiJxYwPRo82jlCXVWHGmqMoKquUuiQis8JwQ0TUxKws5Vg5pSc8VVZIzSvBKxuOQxR5ewailsJwQ0TUDFrbKfHFv0JhKRew41QW5m09xYBD1EIYboiImkk3H0e8P74rBAH47s9LDDhELYThhoioGT0U6o0PH/o74MzdepJ3ECdqZgw3RETN7OGePvhoQggEAfjvn+kMOETNjOGGiKgFTAj11gWc7w+l47WfjqNSw6sYEzUHhhsiohYyIdQbH08IgUwANiRcxhOrjkDN08SJmhzDDRFRC3oo1BtfTe4Ja0s5fj+fh4eXx+Py9VKpyyIyKQw3REQtLCLQDRueCYervRLJ2UUYueR3fPfnJZ5JRdREGG6IiCQQ5KXClpn90L2NI4rKqzB3y0nMWJOAwlIepiK6Vww3REQS8XS0xsZn+mLe6EAo5DL8diYbEf+Ow9akK5zFIboHDDdERBKSywQ80b8tNj3XF/7OtsgtKseL65Lw2MpDOJullro8IqMkiGb23wO1Wg2VSoXCwkI4ODhIXQ4RkU55lQYr91/E0r0pKKusPk38/mB3/N/Q9ujkzn+vyLw15Pc3ww0RkYHJyC/F+7+exS8nMnVtI4OqQ05nD/67ReaJ4aYODDdEZCzOZqnxeWwKtp/MRM2/1D3aOOKhUG+MDvaEysZS2gKJWhDDTR0YbojI2JzLLsKnsefx64lM1Ny1QWEhw7DObogIdEVXb0e0bW0LmUyQtlCiZsRwUweGGyIyVjlFZdh67Cp+SryMs1lFetvslBYI8nJAV29HBHup0MHNHl6trGGntJCoWqKmxXBTB4YbIjIFp64W4uekqzh66TpOXS3ULUD+p1Y2lnCxV8LRWgGVjSVU1pZwtLaEo40l7K0sYaOQw1ZpAWuFHLYKC933tgo5bJQWsLGUc0aIDEJDfn8z0hMRGaEunip08VQBAKo0WqTkFuP45UKcuFyI41cKcelaCQpKK3H95uNeWFvKYauUw+Zm+LGylMPKUgYrSzmUFtVfrSxuaavZbqHft6ZNqdcmh5XF33+WM0hREzCImZtly5bho48+QlZWFkJCQvD555+jd+/ed+y/YcMGzJ07F2lpaWjfvj0++OAD3H///fV6Lc7cEJG5KCqrxOXrN5BfUoGC0koU3Kj+qr5RieulFSgp16CkogqlNV8rNCgpv/m1ogpS/HawlAtQyGVQWMhgefOrwkKma1Pc0lazXVlLW239FXIZLG9+VdbS31IuQC4TYCGTQS4XYCGr+f6W9pvfczar5RnVzM369esxe/ZsrFixAmFhYViyZAkiIyORnJwMV1fX2/ofPHgQkyZNQkxMDEaPHo0ffvgB48aNQ2JiIoKCgiR4B0REhsneyhKdPRp3RpUoiiiv0uqFnZJyDUorqlBWqUVZpab6UaVFec2fa9qrbvlzpRblVXfeXl6pRYXm70NqlRoRlRoNSio0TTUMzUIQUGvo0X2V36H91v7yO4cn/e367XKZAJlQ/ZDLAEGoacMt7Te/1/XV3yYI0Hse2a3f39xXLggQbtlWn9ep3gewspTDxV4p3d+P1DM3YWFh6NWrF5YuXQoA0Gq18PHxwQsvvIDXX3/9tv4TJ05ESUkJtm3bpmvr06cPunXrhhUrVtz19ThzQ0RkWDRa8WYAqg48FVXVgUfv681Hpaa6rfzW76tu6XuH/hVV/9hHc2uf6iCn0WpRpRWh0Yq6rxqt5Ac3jFL3No7Y/Fy/Jn1Oo5m5qaioQEJCAqKjo3VtMpkMERERiI+Pr3Wf+Ph4zJ49W68tMjISW7ZsqbV/eXk5ysvLdd+r1bycORGRIZHLhJvreaSu5HaiqB92/v6qrf6quUN7zfeaO7Rrxeowddv+4t8hS1N7u1YrQisCGlHU1acVcbNdhEYEtKL49/fa6vdRs+3vfURotbjZ/o/n0IoQb76GVrz5Z90+d3t9EUoLae/uJGm4ycvLg0ajgZubm167m5sbzp49W+s+WVlZtfbPysqqtX9MTAwWLFjQNAUTEZFZEYTqw0MWcqkroYYw+RtnRkdHo7CwUPfIyMiQuiQiIiJqRpLO3Dg7O0MulyM7O1uvPTs7G+7u7rXu4+7u3qD+SqUSSqV0i5qIiIioZUk6c6NQKBAaGorY2Fhdm1arRWxsLMLDw2vdJzw8XK8/AOzevfuO/YmIiMi8SH4q+OzZszF16lT07NkTvXv3xpIlS1BSUoKoqCgAwJQpU+Dl5YWYmBgAwIsvvohBgwbhk08+wahRo7Bu3TocPXoUX331lZRvg4iIiAyE5OFm4sSJyM3Nxbx585CVlYVu3bphx44dukXD6enpkMn+nmDq27cvfvjhB7z11lt444030L59e2zZsoXXuCEiIiIABnCdm5bG69wQEREZn4b8/jb5s6WIiIjIvDDcEBERkUlhuCEiIiKTwnBDREREJoXhhoiIiEwKww0RERGZFIYbIiIiMikMN0RERGRSJL9CcUuruWahWq2WuBIiIiKqr5rf2/W59rDZhZuioiIAgI+Pj8SVEBERUUMVFRVBpVLV2cfsbr+g1Wpx9epV2NvbQxCEJn1utVoNHx8fZGRk8NYOd8GxahiOV/1xrOqPY9UwHK/6a46xEkURRUVF8PT01LvnZG3MbuZGJpPB29u7WV/DwcGBH/x64lg1DMer/jhW9cexahiOV/019VjdbcamBhcUExERkUlhuCEiIiKTwnDThJRKJebPnw+lUil1KQaPY9UwHK/641jVH8eqYThe9Sf1WJndgmIiIiIybZy5ISIiIpPCcENEREQmheGGiIiITArDDREREZkUhpsmsmzZMvj5+cHKygphYWE4fPiw1CUZhLfffhuCIOg9OnXqpNteVlaGmTNnonXr1rCzs8NDDz2E7OxsCStuOfv378eYMWPg6ekJQRCwZcsWve2iKGLevHnw8PCAtbU1IiIicP78eb0++fn5ePzxx+Hg4ABHR0c8+eSTKC4ubsF30TLuNlbTpk277XM2YsQIvT7mMlYxMTHo1asX7O3t4erqinHjxiE5OVmvT31+7tLT0zFq1CjY2NjA1dUVr7zyCqqqqlryrbSI+ozX4MGDb/t8PfPMM3p9zGG8li9fjq5du+ouzBceHo5ff/1Vt92QPlcMN01g/fr1mD17NubPn4/ExESEhIQgMjISOTk5UpdmELp06YLMzEzd48CBA7ptL730Ev73v/9hw4YNiIuLw9WrVzF+/HgJq205JSUlCAkJwbJly2rd/uGHH+Kzzz7DihUrcOjQIdja2iIyMhJlZWW6Po8//jhOnTqF3bt3Y9u2bdi/fz+eeuqplnoLLeZuYwUAI0aM0PucrV27Vm+7uYxVXFwcZs6ciT///BO7d+9GZWUlhg8fjpKSEl2fu/3caTQajBo1ChUVFTh48CBWr16NVatWYd68eVK8pWZVn/ECgBkzZuh9vj788EPdNnMZL29vb7z//vtISEjA0aNHcd9992Hs2LE4deoUAAP7XIl0z3r37i3OnDlT971GoxE9PT3FmJgYCasyDPPnzxdDQkJq3VZQUCBaWlqKGzZs0LWdOXNGBCDGx8e3UIWGAYC4efNm3fdarVZ0d3cXP/roI11bQUGBqFQqxbVr14qiKIqnT58WAYhHjhzR9fn1119FQRDEK1eutFjtLe2fYyWKojh16lRx7Nixd9zHXMdKFEUxJydHBCDGxcWJoli/n7vt27eLMplMzMrK0vVZvny56ODgIJaXl7fsG2hh/xwvURTFQYMGiS+++OId9zHn8WrVqpX49ddfG9znijM396iiogIJCQmIiIjQtclkMkRERCA+Pl7CygzH+fPn4enpCX9/fzz++ONIT08HACQkJKCyslJv7Dp16oQ2bdqY/dilpqYiKytLb2xUKhXCwsJ0YxMfHw9HR0f07NlT1yciIgIymQyHDh1q8Zqltm/fPri6uqJjx4549tlnce3aNd02cx6rwsJCAICTkxOA+v3cxcfHIzg4GG5ubro+kZGRUKvVuv+lm6p/jleN77//Hs7OzggKCkJ0dDRKS0t128xxvDQaDdatW4eSkhKEh4cb3OfK7G6c2dTy8vKg0Wj0/rIAwM3NDWfPnpWoKsMRFhaGVatWoWPHjsjMzMSCBQswYMAAnDx5EllZWVAoFHB0dNTbx83NDVlZWdIUbCBq3n9tn6uabVlZWXB1ddXbbmFhAScnJ7MbvxEjRmD8+PFo27YtLly4gDfeeAMjR45EfHw85HK52Y6VVqvFrFmz0K9fPwQFBQFAvX7usrKyav3s1WwzVbWNFwA89thj8PX1haenJ44fP47XXnsNycnJ2LRpEwDzGq8TJ04gPDwcZWVlsLOzw+bNmxEYGIikpCSD+lwx3FCzGjlypO7PXbt2RVhYGHx9ffHjjz/C2tpawsrIlDz66KO6PwcHB6Nr165o164d9u3bh6FDh0pYmbRmzpyJkydP6q1zozu703jdujYrODgYHh4eGDp0KC5cuIB27dq1dJmS6tixI5KSklBYWIiNGzdi6tSpiIuLk7qs2/Cw1D1ydnaGXC6/bUV4dnY23N3dJarKcDk6OqJDhw5ISUmBu7s7KioqUFBQoNeHYwfd+6/rc+Xu7n7bovWqqirk5+eb/fj5+/vD2dkZKSkpAMxzrJ5//nls27YNe/fuhbe3t669Pj937u7utX72araZojuNV23CwsIAQO/zZS7jpVAoEBAQgNDQUMTExCAkJASffvqpwX2uGG7ukUKhQGhoKGJjY3VtWq0WsbGxCA8Pl7Ayw1RcXIwLFy7Aw8MDoaGhsLS01Bu75ORkpKenm/3YtW3bFu7u7npjo1arcejQId3YhIeHo6CgAAkJCbo+e/bsgVar1f3ja64uX76Ma9euwcPDA4B5jZUoinj++eexefNm7NmzB23bttXbXp+fu/DwcJw4cUIvEO7evRsODg4IDAxsmTfSQu42XrVJSkoCAL3Pl7mM1z9ptVqUl5cb3ueqSZcnm6l169aJSqVSXLVqlXj69GnxqaeeEh0dHfVWhJurOXPmiPv27RNTU1PFP/74Q4yIiBCdnZ3FnJwcURRF8ZlnnhHbtGkj7tmzRzx69KgYHh4uhoeHS1x1yygqKhKPHTsmHjt2TAQgLl68WDx27Jh46dIlURRF8f333xcdHR3FrVu3isePHxfHjh0rtm3bVrxx44buOUaMGCF2795dPHTokHjgwAGxffv24qRJk6R6S82mrrEqKioSX375ZTE+Pl5MTU0Vf/vtN7FHjx5i+/btxbKyMt1zmMtYPfvss6JKpRL37dsnZmZm6h6lpaW6Pnf7uauqqhKDgoLE4cOHi0lJSeKOHTtEFxcXMTo6Woq31KzuNl4pKSniO++8Ix49elRMTU0Vt27dKvr7+4sDBw7UPYe5jNfrr78uxsXFiampqeLx48fF119/XRQEQdy1a5coiob1uWK4aSKff/652KZNG1GhUIi9e/cW//zzT6lLMggTJ04UPTw8RIVCIXp5eYkTJ04UU1JSdNtv3LghPvfcc2KrVq1EGxsb8cEHHxQzMzMlrLjl7N27VwRw22Pq1KmiKFafDj537lzRzc1NVCqV4tChQ8Xk5GS957h27Zo4adIk0c7OTnRwcBCjoqLEoqIiCd5N86prrEpLS8Xhw4eLLi4uoqWlpejr6yvOmDHjtv9cmMtY1TZOAMT//Oc/uj71+blLS0sTR44cKVpbW4vOzs7inDlzxMrKyhZ+N83vbuOVnp4uDhw4UHRychKVSqUYEBAgvvLKK2JhYaHe85jDeD3xxBOir6+vqFAoRBcXF3Ho0KG6YCOKhvW5EkRRFJt2LoiIiIhIOlxzQ0RERCaF4YaIiIhMCsMNERERmRSGGyIiIjIpDDdERERkUhhuiIiIyKQw3BAREZFJYbghIrPg5+eHJUuWSF0GEbUAhhsianLTpk3DuHHjAACDBw/GrFmzWuy1V61aBUdHx9vajxw5ond3ZyIyXRZSF0BEVB8VFRVQKBSN3t/FxaUJqyEiQ8aZGyJqNtOmTUNcXBw+/fRTCIIAQRCQlpYGADh58iRGjhwJOzs7uLm5YfLkycjLy9PtO3jwYDz//POYNWsWnJ2dERkZCQBYvHgxgoODYWtrCx8fHzz33HMoLi4GAOzbtw9RUVEoLCzUvd7bb78N4PbDUunp6Rg7dizs7Ozg4OCARx55BNnZ2brtb7/9Nrp164bvvvsOfn5+UKlUePTRR1FUVKTrs3HjRgQHB8Pa2hqtW7dGREQESkpKmmk0iai+GG6IqNl8+umnCA8Px4wZM5CZmYnMzEz4+PigoKAA9913H7p3746jR49ix44dyM7OxiOPPKK3/+rVq6FQKPDHH39gxYoVAACZTIbPPvsMp06dwurVq7Fnzx68+uqrAIC+fftiyZIlcHBw0L3eyy+/fFtdWq0WY8eORX5+PuLi4rB7925cvHgREydO1Ot34cIFbNmyBdu2bcO2bdsQFxeH999/HwCQmZmJSZMm4YknnsCZM2ewb98+jB8/HrxdH5H0eFiKiJqNSqWCQqGAjY0N3N3dde1Lly5F9+7dsWjRIl3bt99+Cx8fH5w7dw4dOnQAALRv3x4ffvih3nPeun7Hz88P7777Lp555hl88cUXUCgUUKlUEARB7/X+KTY2FidOnEBqaip8fHwAAGvWrEGXLl1w5MgR9OrVC0B1CFq1ahXs7e0BAJMnT0ZsbCzee+89ZGZmoqqqCuPHj4evry8AIDg4+B5Gi4iaCmduiKjF/fXXX9i7dy/s7Ox0j06dOgGoni2pERoaetu+v/32G4YOHQovLy/Y29tj8uTJuHbtGkpLS+v9+mfOnIGPj48u2ABAYGAgHB0dcebMGV2bn5+fLtgAgIeHB3JycgAAISEhGDp0KIKDg/Hwww9j5cqVuH79ev0HgYiaDcMNEbW44uJijBkzBklJSXqP8+fPY+DAgbp+tra2evulpaVh9OjR6Nq1K3766SckJCRg2bJlAKoXHDc1S0tLve8FQYBWqwUAyOVy7N69G7/++isCAwPx+eefo2PHjkhNTW3yOoioYRhuiKhZKRQKaDQavbYePXrg1KlT8PPzQ0BAgN7jn4HmVgkJCdBqtfjkk0/Qp08fdOjQAVevXr3r6/1T586dkZGRgYyMDF3b6dOnUVBQgMDAwHq/N0EQ0K9fPyxYsADHjh2DQqHA5s2b670/ETUPhhsialZ+fn44dOgQ0tLSkJeXB61Wi5kzZyI/Px+TJk3CkSNHcOHCBezcuRNRUVF1BpOAgABUVlbi888/x8WLF/Hdd9/pFhrf+nrFxcWIjY1FXl5erYerIiIiEBwcjMcffxyJiYk4fPgwpkyZgkGDBqFnz571el+HDh3CokWLcPToUaSnp2PTpk3Izc1F586dGzZARNTkGG6IqFm9/PLLkMvlCAwMhIuLC9LT0+Hp6Yk//vgDGo0Gw4cPR3BwMGbNmgVHR0fIZHf+ZykkJASLFy/GBx98gKCgIHz//feIiYnR69O3b18888wzmDhxIlxcXG5bkAxUz7hs3boVrVq1wsCBAxEREQF/f3+sX7++3u/LwcEB+/fvx/33348OHTrgrbfewieffIKRI0fWf3CIqFkIIs9bJCIiIhPCmRsiIiIyKQw3REREZFIYboiIiMikMNwQERGRSWG4ISIiIpPCcENEREQmheGGiIiITArDDREREZkUhhsiIiIyKQw3REREZFIYboiIiMikMNwQERGRSfl/UroqWfBahH4AAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "plt.plot(losses)\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.xlabel(\"Iterations\")\n",
        "plt.title(\"Loss Per Iteration\")\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j7u-QXzLE1DJ"
      },
      "source": [
        "Look at the predictions and the true values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D5Q54NPUE1DJ",
        "outputId": "78822479-b295-4a94-ee4c-130729aff40b"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(tensor([1.]), 1.0349581241607666),\n",
              " (tensor([0.]), 0.0129433274269104),\n",
              " (tensor([0.]), -0.0032622218132019043),\n",
              " (tensor([1.]), 0.9480294585227966)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "list(zip(outputs, [y.item() for y in predictions]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "Z_iUBLLZE1DJ"
      },
      "source": [
        "<!-- BEGIN QUESTION -->\n",
        "\n",
        "**Question 4:**\n",
        "\n",
        "Compare the loss curves and number of iterations between the PyTorch implemenation  and the manual implementation.\n",
        "\n",
        "What differences do you see?\n",
        "\n",
        "To what do you attribute the differences?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIhPTPhFE1DJ"
      },
      "source": [
        "Answer:\n",
        "\n",
        "Torch SGD the loss curve has a gradual loss decrease, compare to the manual implementation.\n",
        "\n",
        "Torch SGD first go down hill fast then hit some saddle point and the drop is slow down (iteration 10-50), until iteration 100, the drop in loss starts to accelerate again (iteration 100 - 150), after iteration 200 the loss tails off\n",
        "\n",
        "I think differences are:\n",
        "\n",
        "1. SGD uses adaptive step sizes, while manual one use the fixed and big learning rate $\\alpha=0.01$\n",
        "\n",
        "2. pytorch might clip the large gradient, so the progress is gradual\n",
        "\n",
        "\n",
        "3.   SGD uses mini batch and sub sample, not all the data points to calucate the gradient, so it's going to be unstable loss curve, but it's faster. manual version use the full data as full batch to calcuate the gradient\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "deletable": false,
        "editable": false,
        "id": "dvreiOBfE1DK"
      },
      "source": [
        "---\n",
        "\n",
        "<div style=\"text-align: center;\">\n",
        "<b>The End</b>\n",
        "</div>\n",
        "\n",
        "---\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "za2p4CD7zPmS"
      },
      "execution_count": 38,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "dl4ds",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.4"
    },
    "otter": {
      "OK_FORMAT": true,
      "assignment_name": "hw4_backpropagation",
      "tests": {
        "q1": {
          "name": "q1",
          "points": 4,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> assert np.isclose(net_output[0, 0], 1.907, atol=0.001), 'Incorrect output'\n",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> K = 5\n>>> D = 6\n>>> D_i = 3\n>>> D_o = 1\n>>> np.random.seed(42)\n>>> all_weights, all_biases = create_network(K, D, D_i, D_o)\n>>> net_input = np.ones((D_i, 4)) * 1.9\n>>> net_output, all_f, all_h = forward_pass(net_input, all_weights, all_biases)\n>>> assert np.allclose(net_output, np.array([[-2.226, -2.226, -2.226, -2.226]]), atol=0.001), 'Incorrect output'\n",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        },
        "q2": {
          "name": "q2",
          "points": 5,
          "suites": [
            {
              "cases": [
                {
                  "code": ">>> assert np.allclose(all_dl_dbiases_fd[layer], all_dl_dbiases[layer], rtol=1e-05, atol=1e-08, equal_nan=False), 'Derivatives do not match'\n",
                  "hidden": false,
                  "locked": false
                },
                {
                  "code": ">>> assert np.allclose(all_dl_dweights_fd[layer], all_dl_dweights[layer], rtol=1e-05, atol=1e-08, equal_nan=False), 'Derivatives do not match'\n",
                  "hidden": false,
                  "locked": false
                }
              ],
              "scored": true,
              "setup": "",
              "teardown": "",
              "type": "doctest"
            }
          ]
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}